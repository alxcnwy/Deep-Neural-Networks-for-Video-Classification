{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T06:33:54.878279Z",
     "start_time": "2020-03-24T06:33:54.875321Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T06:33:54.885171Z",
     "start_time": "2020-03-24T06:33:54.880292Z"
    }
   },
   "outputs": [],
   "source": [
    "# whether to log each feature and sequence status\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T06:33:55.500556Z",
     "start_time": "2020-03-24T06:33:54.887070Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T06:33:55.505890Z",
     "start_time": "2020-03-24T06:33:55.502922Z"
    }
   },
   "outputs": [],
   "source": [
    "# setup paths\n",
    "pwd = os.getcwd().replace(\"notebooks\",\"\")\n",
    "path_cache = pwd + 'cache/'\n",
    "path_data = pwd + 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T06:33:55.516009Z",
     "start_time": "2020-03-24T06:33:55.507948Z"
    }
   },
   "outputs": [],
   "source": [
    "# setup logging\n",
    "# any explicit log messages or uncaught errors to stdout and file /logs.log\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(threadName)-12.12s] [%(levelname)-5.5s]  %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"{0}/{1}.log\".format(pwd, \"logs\")),\n",
    "        logging.StreamHandler()\n",
    "    ])\n",
    "# init logger\n",
    "logger = logging.getLogger()\n",
    "# make logger aware of any uncaught exceptions\n",
    "def handle_exception(exc_type, exc_value, exc_traceback):\n",
    "    if issubclass(exc_type, KeyboardInterrupt):\n",
    "        sys.__excepthook__(exc_type, exc_value, exc_traceback)\n",
    "        return\n",
    "\n",
    "    logger.error(\"Uncaught exception\", exc_info=(exc_type, exc_value, exc_traceback))\n",
    "sys.excepthook = handle_exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T06:33:59.081377Z",
     "start_time": "2020-03-24T06:33:55.518073Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from deepvideoclassification.architectures import Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model Params from Experiments Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T06:33:59.086821Z",
     "start_time": "2020-03-24T06:33:59.083681Z"
    }
   },
   "outputs": [],
   "source": [
    "experiment1 = {\n",
    "             'architecture': 'video_lrcnn_frozen',\n",
    "             'dropout': 0.2,\n",
    "             'layer_1_size': 256,\n",
    "             'layer_2_size': 512,\n",
    "             'layer_3_size': 256,\n",
    "             'model_id': 1,\n",
    "             'pooling': 'max',\n",
    "             'pretrained_model_name': 'vgg16',\n",
    "             'sequence_length': 20,\n",
    "             'sequence_model': \"LSTM\",\n",
    "             'sequence_model_layers': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T06:33:59.097061Z",
     "start_time": "2020-03-24T06:33:59.088838Z"
    }
   },
   "outputs": [],
   "source": [
    "experiment2 = {\n",
    "             'architecture': 'video_lrcnn_frozen',\n",
    "             'dropout': 0.2,\n",
    "             'layer_1_size': 256,\n",
    "             'layer_2_size': 128,\n",
    "             'layer_3_size': 256,\n",
    "             'model_id': 2,\n",
    "             'pooling': 'max',\n",
    "             'pretrained_model_name': 'vgg16',\n",
    "             'sequence_length': 20,\n",
    "             'sequence_model': \"SimpleRNN\",\n",
    "             'sequence_model_layers': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T06:33:59.102320Z",
     "start_time": "2020-03-24T06:33:59.098895Z"
    }
   },
   "outputs": [],
   "source": [
    "experiment3 = {\n",
    "             'architecture': 'video_lrcnn_frozen',\n",
    "             'dropout': 0.2,\n",
    "             'layer_1_size': 256,\n",
    "             'layer_2_size': 512,\n",
    "             'layer_3_size': 256,\n",
    "             'model_id': 3,\n",
    "             'pooling': 'max',\n",
    "             'pretrained_model_name': 'vgg16',\n",
    "             'sequence_length': 10,\n",
    "             'sequence_model': \"LSTM\",\n",
    "             'sequence_model_layers': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T06:33:59.108875Z",
     "start_time": "2020-03-24T06:33:59.104214Z"
    }
   },
   "outputs": [],
   "source": [
    "experiment4 = {\n",
    "             'architecture': 'video_lrcnn_frozen',\n",
    "             'dropout': 0.2,\n",
    "             'layer_1_size': 256,\n",
    "             'layer_2_size': 512,\n",
    "             'layer_3_size': 256,\n",
    "             'model_id': 4,\n",
    "             'pooling': 'max',\n",
    "             'pretrained_model_name': 'vgg16',\n",
    "             'sequence_length': 20,\n",
    "             'sequence_model': \"SimpleRNN\",\n",
    "             'sequence_model_layers': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T06:33:59.114027Z",
     "start_time": "2020-03-24T06:33:59.110716Z"
    }
   },
   "outputs": [],
   "source": [
    "experiment5 = {\n",
    "             'architecture': 'video_lrcnn_frozen',\n",
    "             'dropout': 0.2,\n",
    "             'layer_1_size': 256,\n",
    "             'layer_2_size': 128,\n",
    "             'layer_3_size': 0,\n",
    "             'model_id': 5,\n",
    "             'pooling': 'max',\n",
    "             'pretrained_model_name': 'vgg16',\n",
    "             'sequence_length': 10,\n",
    "             'sequence_model': \"SimpleRNN\",\n",
    "             'sequence_model_layers': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T06:33:59.118942Z",
     "start_time": "2020-03-24T06:33:59.115960Z"
    }
   },
   "outputs": [],
   "source": [
    "experiment6 = {\n",
    "             'architecture': 'image_mlp_frozen',\n",
    "             'dropout': 0.2,\n",
    "             'layer_1_size': 128,\n",
    "             'layer_2_size': 256,\n",
    "             'layer_3_size': 256,\n",
    "             'model_id': 6,\n",
    "             'pooling': 'max',\n",
    "             'pretrained_model_name': 'resnet50',\n",
    "             'sequence_length': 1,\n",
    "             'sequence_model': \"\",\n",
    "             'sequence_model_layers': \"\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T06:33:59.124034Z",
     "start_time": "2020-03-24T06:33:59.120919Z"
    }
   },
   "outputs": [],
   "source": [
    "experiment7 = {\n",
    "             'architecture': 'video_mlp_concat',\n",
    "             'dropout': 0.2,\n",
    "             'layer_1_size': 128,\n",
    "             'layer_2_size': 128,\n",
    "             'layer_3_size': 128,\n",
    "             'model_id': 7,\n",
    "             'pooling': 'max',\n",
    "             'pretrained_model_name': 'resnet50',\n",
    "             'sequence_length': 3,\n",
    "             'sequence_model': \"\",\n",
    "             'sequence_model_layers': \"\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T06:34:02.099538Z",
     "start_time": "2020-03-24T06:34:02.096852Z"
    }
   },
   "outputs": [],
   "source": [
    "experiment = experiment6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T06:37:27.882551Z",
     "start_time": "2020-03-24T06:34:09.645024Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-24 06:34:09,648 [MainThread  ] [INFO ]  Begin experiment for model_id=6 on GPU:1 \n",
      "2020-03-24 06:34:09,655 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6   XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "{'model_id': 6, 'sequence_model_layers': '', 'dropout': 0.2, 'pooling': 'max', 'layer_1_size': 128, 'sequence_length': 1, 'pretrained_model_name': 'resnet50', 'sequence_model': '', 'architecture': 'image_mlp_frozen', 'layer_3_size': 256, 'layer_2_size': 256}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-24 06:34:11,107 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/resnet50/max/\n",
      "2020-03-24 06:34:11,109 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=42217, valid=7200, test=3600\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.93145, saving model to /mnt/seals/models/6/model_round_1.h5\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.93145 to 0.93355, saving model to /mnt/seals/models/6/model_round_1.h5\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.93355 to 0.94177, saving model to /mnt/seals/models/6/model_round_1.h5\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.94177\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.94177\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.94177 to 0.94528, saving model to /mnt/seals/models/6/model_round_1.h5\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.94528\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.94528\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.94528\n",
      "Epoch 00009: early stopping\n",
      "H1 {'acc': [0.9257239153664316, 0.9403118093168448, 0.9433911366388952, 0.945414693958652, 0.9469780455512783, 0.9488053389509, 0.9502705575817416, 0.9508221296645477, 0.9515835006868923], 'val_loss': [0.16639399704005983, 0.16050477971633276, 0.15673680977688895, 0.14806815769937304, 0.14590051614575916, 0.14395631276898913, 0.14943019739455646, 0.15627870917320252, 0.1555376915799247], 'loss': [0.1884463785057069, 0.149469553025835, 0.14164506993199705, 0.135533826005951, 0.1310798287159411, 0.12656638988775484, 0.12457680540374609, 0.12253279791083835, 0.12013962991096397], 'val_acc': [0.93144843366411, 0.9335516068670485, 0.94176589012146, 0.9411904954910278, 0.9396428770489162, 0.9452777936723498, 0.9420039881600274, 0.9390674797693889, 0.9389285898208618]}\n",
      "stopped_epoch1 6\n",
      "9\n",
      "0.9420039881600274\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.94748, saving model to /mnt/seals/models/6/model_round_2.h5\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.94748 to 0.94859, saving model to /mnt/seals/models/6/model_round_2.h5\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.94859\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.94859 to 0.94877, saving model to /mnt/seals/models/6/model_round_2.h5\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.94877\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.94877\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.94877\n",
      "Epoch 00007: early stopping\n",
      "H2 {'acc': [0.957931654519974, 0.9584189309113672, 0.9597217241151196, 0.9599247579197109, 0.9599146046750195, 0.9603545084307307, 0.960879009631847], 'val_loss': [0.13946596814526452, 0.13756043564942147, 0.14110379283626875, 0.13815984305408266, 0.145434743579891, 0.14142090578873953, 0.1429975504345364], 'loss': [0.1031106437023048, 0.10026263313059426, 0.09827652102393689, 0.09766003494771164, 0.09696175320882298, 0.09525646228342101, 0.09484643801903118], 'val_acc': [0.9474801754951477, 0.948591288195716, 0.9469444643126593, 0.9487698602676392, 0.9437500172191196, 0.9468254144986471, 0.9477579530080159]}\n",
      "stopped_epoch2 4\n",
      "7\n",
      "0.9437500172191196\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.94716, saving model to /mnt/seals/models/6/model_round_3.h5\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.94716 to 0.94752, saving model to /mnt/seals/models/6/model_round_3.h5\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.94752 to 0.94760, saving model to /mnt/seals/models/6/model_round_3.h5\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.94760 to 0.94792, saving model to /mnt/seals/models/6/model_round_3.h5\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.94792\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.94792 to 0.94835, saving model to /mnt/seals/models/6/model_round_3.h5\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.94835\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.94835\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.94835\n",
      "Epoch 00009: early stopping\n",
      "H3 {'acc': [0.9612580042824886, 0.9615693211055681, 0.961829878274592, 0.9619483148526171, 0.9617148275798022, 0.9615862393369611, 0.9616708359437193, 0.9619178593061304, 0.9614711889513694], 'val_loss': [0.14208276318179236, 0.14160739512907133, 0.14169627673096127, 0.14100654035806656, 0.143317089246379, 0.14178783771064546, 0.14213821250531408, 0.14301924685637157, 0.14254057973623277], 'loss': [0.0929168945835215, 0.09228227803628807, 0.09182462307252603, 0.09184082369734058, 0.09177942353349923, 0.09204895830658878, 0.09136615643977475, 0.09167553937588496, 0.09182253152175802], 'val_acc': [0.9471627179781595, 0.94751985973782, 0.947599225838979, 0.947916685740153, 0.9476785887612237, 0.9483531943957011, 0.9479960521062215, 0.9473611323038736, 0.9479960515764024]}\n",
      "stopped_epoch3 6\n",
      "9\n",
      "0.9479960521062215\n",
      "best fit round 3 0.9479960521062215\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 7)                 1799      \n",
      "=================================================================\n",
      "Total params: 362,887\n",
      "Trainable params: 362,887\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3600/3600 [==============================] - 0s 65us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-24 06:37:25,475 [MainThread  ] [INFO ]  {\n",
      "    \"architecture\": \"image_mlp_frozen\",\n",
      "    \"batch_size\": 32,\n",
      "    \"class_names\": \"\",\n",
      "    \"convolution_kernel_size\": 3,\n",
      "    \"data_total_rows_test\": 3600,\n",
      "    \"data_total_rows_train\": 42217,\n",
      "    \"data_total_rows_valid\": 7200,\n",
      "    \"dropout\": 0.2,\n",
      "    \"fit_best_round\": 3,\n",
      "    \"fit_dt_test_duration_seconds\": \"0\",\n",
      "    \"fit_dt_test_end\": \"2020-03-24 06:37:23\",\n",
      "    \"fit_dt_test_start\": \"2020-03-24 06:37:23\",\n",
      "    \"fit_dt_train_duration_seconds\": \"190\",\n",
      "    \"fit_dt_train_end\": \"2020-03-24 06:37:23\",\n",
      "    \"fit_dt_train_start\": \"2020-03-24 06:34:12\",\n",
      "    \"fit_num_epochs\": 19,\n",
      "    \"fit_stopped_epoch1\": 6,\n",
      "    \"fit_stopped_epoch2\": 4,\n",
      "    \"fit_stopped_epoch3\": 6,\n",
      "    \"fit_test_acc\": 0.8061111111111111,\n",
      "    \"fit_train_acc\": 0.9616708359437193,\n",
      "    \"fit_train_loss\": 0.09136615643977475,\n",
      "    \"fit_val_acc\": 0.9479960521062215,\n",
      "    \"fit_val_loss\": 0.14213821250531408,\n",
      "    \"frame_size\": [\n",
      "        224,\n",
      "        224\n",
      "    ],\n",
      "    \"layer_1_size\": 128,\n",
      "    \"layer_2_size\": 256,\n",
      "    \"layer_3_size\": 256,\n",
      "    \"model_id\": 6,\n",
      "    \"model_param_count\": 362887,\n",
      "    \"model_weights_path\": null,\n",
      "    \"num_features\": 2048,\n",
      "    \"path_model\": \"/mnt/seals/models/6/\",\n",
      "    \"pooling\": \"max\",\n",
      "    \"pretrained_model_name\": \"resnet50\",\n",
      "    \"sequence_length\": 1,\n",
      "    \"sequence_model\": \"\",\n",
      "    \"sequence_model_layers\": \"\",\n",
      "    \"verbose\": true\n",
      "}\n",
      "2020-03-24 06:37:25,476 [MainThread  ] [INFO ]  model 6 test acc: 0.8061111111111111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_train_loss': 0.09136615643977475, 'model_weights_path': None, 'sequence_model': '', 'data_total_rows_valid': 7200, 'architecture': 'image_mlp_frozen', 'fit_stopped_epoch2': 4, 'num_features': 2048, 'frame_size': (224, 224), 'fit_val_loss': 0.14213821250531408, 'pretrained_model_name': 'resnet50', 'pooling': 'max', 'fit_dt_test_end': '2020-03-24 06:37:23', 'dropout': 0.2, 'fit_dt_train_end': '2020-03-24 06:37:23', 'fit_stopped_epoch3': 6, 'batch_size': 32, 'data_total_rows_train': 42217, 'fit_best_round': 3, 'model_id': 6, 'convolution_kernel_size': 3, 'data_total_rows_test': 3600, 'fit_dt_train_duration_seconds': '190', 'layer_2_size': 256, 'verbose': True, 'fit_dt_test_duration_seconds': '0', 'sequence_model_layers': '', 'path_model': '/mnt/seals/models/6/', 'class_names': '', 'fit_val_acc': 0.9479960521062215, 'model_param_count': 362887, 'fit_num_epochs': 19, 'sequence_length': 1, 'fit_stopped_epoch1': 6, 'fit_test_acc': 0.8061111111111111, 'layer_3_size': 256, 'fit_dt_train_start': '2020-03-24 06:34:12', 'layer_1_size': 128, 'fit_train_acc': 0.9616708359437193, 'fit_dt_test_start': '2020-03-24 06:37:23'}\n",
      "gsutil -m rsync -r /mnt/seals/models/6/ gs://thesis-penguins/models/6/\n",
      "XX\n",
      "upload error\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9417"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(str(experiment[\"model_id\"]) + \"   \" + \"X\"*60)\n",
    "logging.info(\"Begin experiment for model_id={} on GPU:{} \".format(experiment['model_id'], os.environ[\"CUDA_VISIBLE_DEVICES\"]))\n",
    "print(experiment)\n",
    "\n",
    "architecture = Architecture(model_id = experiment['model_id'], \n",
    "                            architecture = experiment['architecture'], \n",
    "                            sequence_length = experiment['sequence_length'], \n",
    "                            pretrained_model_name = experiment['pretrained_model_name'],\n",
    "                            pooling = experiment['pooling'],\n",
    "                            sequence_model = experiment['sequence_model'],\n",
    "                            sequence_model_layers = experiment['sequence_model_layers'],\n",
    "                            layer_1_size = experiment['layer_1_size'],\n",
    "                            layer_2_size = experiment['layer_2_size'],\n",
    "                            layer_3_size = experiment['layer_3_size'],\n",
    "                            dropout = experiment['dropout'],\n",
    "                            verbose=True)\n",
    "\n",
    "architecture.train_model()\n",
    "    \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T08:25:51.176086Z",
     "start_time": "2020-03-23T08:25:51.170992Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 'label_ascent',\n",
       " '1': 'label_bottom',\n",
       " '2': 'label_breath',\n",
       " '3': 'label_descent',\n",
       " '4': 'label_search',\n",
       " '5': 'label_shallow',\n",
       " '6': 'label_subsurface'}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "architecture.data.label_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model and predict on full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T06:38:24.348890Z",
     "start_time": "2020-03-24T06:38:24.344281Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger, TensorBoard\n",
    "from keras.layers import Dense, Flatten, Dropout, ZeroPadding3D, Input\n",
    "from keras.layers.recurrent import SimpleRNN, GRU, LSTM\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling3D, Conv3D, MaxPooling2D, Convolution1D, Convolution3D, MaxPooling3D, ZeroPadding3D\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.optimizers import Adam, RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## video models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T09:44:59.636565Z",
     "start_time": "2020-03-23T09:44:59.633296Z"
    }
   },
   "outputs": [],
   "source": [
    "experiments = [experiment1, experiment2, experiment3, experiment4, experiment5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T06:38:24.358538Z",
     "start_time": "2020-03-24T06:38:24.351014Z"
    }
   },
   "outputs": [],
   "source": [
    "class_names = ['ascent',\n",
    "'bottom',\n",
    "'breath',\n",
    "'descent',\n",
    "'search',\n",
    "'shallow',\n",
    "'subsurface']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T11:24:21.126684Z",
     "start_time": "2020-03-23T09:45:01.518481Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 20\n",
      "predicting frame 0 on video 20150807_no8B_1\n",
      "predicting frame 500 on video 20150807_no8B_1\n",
      "predicting frame 1000 on video 20150807_no8B_1\n",
      "predicting frame 1500 on video 20150807_no8B_1\n",
      "predicting frame 2000 on video 20150807_no8B_1\n",
      "predicting frame 2500 on video 20150807_no8B_1\n",
      "predicting frame 3000 on video 20150807_no8B_1\n",
      "predicting frame 0 on video 20150820_no8B_2\n",
      "predicting frame 500 on video 20150820_no8B_2\n",
      "predicting frame 0 on video 20150820_no8B_3\n",
      "predicting frame 500 on video 20150820_no8B_3\n",
      "predicting frame 1000 on video 20150820_no8B_3\n",
      "predicting frame 1500 on video 20150820_no8B_3\n",
      "predicting frame 2000 on video 20150820_no8B_3\n",
      "predicting frame 2500 on video 20150820_no8B_3\n",
      "predicting frame 3000 on video 20150820_no8B_3\n",
      "predicting frame 0 on video 20150827_no8B_1\n",
      "predicting frame 500 on video 20150827_no8B_1\n",
      "predicting frame 1000 on video 20150827_no8B_1\n",
      "predicting frame 1500 on video 20150827_no8B_1\n",
      "predicting frame 2000 on video 20150827_no8B_1\n",
      "predicting frame 2500 on video 20150827_no8B_1\n",
      "predicting frame 3000 on video 20150827_no8B_1\n",
      "predicting frame 3500 on video 20150827_no8B_1\n",
      "predicting frame 0 on video 20150827_no8B_3\n",
      "predicting frame 500 on video 20150827_no8B_3\n",
      "predicting frame 1000 on video 20150827_no8B_3\n",
      "predicting frame 1500 on video 20150827_no8B_3\n",
      "predicting frame 2000 on video 20150827_no8B_3\n",
      "predicting frame 2500 on video 20150827_no8B_3\n",
      "predicting frame 3000 on video 20150827_no8B_3\n",
      "predicting frame 0 on video 20160801_no9_2\n",
      "predicting frame 500 on video 20160801_no9_2\n",
      "predicting frame 1000 on video 20160801_no9_2\n",
      "predicting frame 1500 on video 20160801_no9_2\n",
      "predicting frame 2000 on video 20160801_no9_2\n",
      "predicting frame 2500 on video 20160801_no9_2\n",
      "predicting frame 3000 on video 20160801_no9_2\n",
      "predicting frame 3500 on video 20160801_no9_2\n",
      "predicting frame 0 on video 20160812_no9_1\n",
      "predicting frame 500 on video 20160812_no9_1\n",
      "predicting frame 1000 on video 20160812_no9_1\n",
      "predicting frame 1500 on video 20160812_no9_1\n",
      "predicting frame 2000 on video 20160812_no9_1\n",
      "predicting frame 2500 on video 20160812_no9_1\n",
      "predicting frame 3000 on video 20160812_no9_1\n",
      "predicting frame 3500 on video 20160812_no9_1\n",
      "predicting frame 0 on video 20160812_no9_2\n",
      "predicting frame 500 on video 20160812_no9_2\n",
      "predicting frame 0 on video 20160812_no9_3\n",
      "predicting frame 500 on video 20160812_no9_3\n",
      "predicting frame 1000 on video 20160812_no9_3\n",
      "predicting frame 1500 on video 20160812_no9_3\n",
      "predicting frame 2000 on video 20160812_no9_3\n",
      "predicting frame 2500 on video 20160812_no9_3\n",
      "predicting frame 3000 on video 20160812_no9_3\n",
      "predicting frame 3500 on video 20160812_no9_3\n",
      "predicting frame 0 on video 20160819_no9_1\n",
      "predicting frame 500 on video 20160819_no9_1\n",
      "predicting frame 1000 on video 20160819_no9_1\n",
      "predicting frame 1500 on video 20160819_no9_1\n",
      "predicting frame 2000 on video 20160819_no9_1\n",
      "predicting frame 2500 on video 20160819_no9_1\n",
      "predicting frame 3000 on video 20160819_no9_1\n",
      "predicting frame 3500 on video 20160819_no9_1\n",
      "predicting frame 0 on video 20160819_no9_3\n",
      "predicting frame 500 on video 20160819_no9_3\n",
      "predicting frame 1000 on video 20160819_no9_3\n",
      "predicting frame 1500 on video 20160819_no9_3\n",
      "predicting frame 2000 on video 20160819_no9_3\n",
      "predicting frame 2500 on video 20160819_no9_3\n",
      "predicting frame 3000 on video 20160819_no9_3\n",
      "predicting frame 3500 on video 20160819_no9_3\n",
      "predicting frame 0 on video 20160819_no9_4\n",
      "predicting frame 500 on video 20160819_no9_4\n",
      "predicting frame 1000 on video 20160819_no9_4\n",
      "predicting frame 1500 on video 20160819_no9_4\n",
      "predicting frame 2000 on video 20160819_no9_4\n",
      "predicting frame 2500 on video 20160819_no9_4\n",
      "predicting frame 3000 on video 20160819_no9_4\n",
      "predicting frame 3500 on video 20160819_no9_4\n",
      "predicting frame 0 on video 20160930_no8_1\n",
      "predicting frame 500 on video 20160930_no8_1\n",
      "predicting frame 1000 on video 20160930_no8_1\n",
      "predicting frame 1500 on video 20160930_no8_1\n",
      "predicting frame 2000 on video 20160930_no8_1\n",
      "predicting frame 2500 on video 20160930_no8_1\n",
      "predicting frame 0 on video 20160930_no8_3\n",
      "predicting frame 3000 on video 20160930_no8_3\n",
      "predicting frame 3500 on video 20160930_no8_3\n",
      "predicting frame 0 on video 20160930_no8_4\n",
      "predicting frame 500 on video 20160930_no8_4\n",
      "predicting frame 1000 on video 20160930_no8_4\n",
      "predicting frame 1500 on video 20160930_no8_4\n",
      "predicting frame 2000 on video 20160930_no8_4\n",
      "predicting frame 2500 on video 20160930_no8_4\n",
      "predicting frame 0 on video 20161005_no9_2\n",
      "predicting frame 500 on video 20161005_no9_2\n",
      "predicting frame 0 on video 20161005_no9_3\n",
      "predicting frame 500 on video 20161005_no9_3\n",
      "predicting frame 1000 on video 20161005_no9_3\n",
      "predicting frame 1500 on video 20161005_no9_3\n",
      "predicting frame 2000 on video 20161005_no9_3\n",
      "predicting frame 2500 on video 20161005_no9_3\n",
      "predicting frame 3000 on video 20161005_no9_3\n",
      "predicting frame 3500 on video 20161005_no9_3\n",
      "predicting frame 0 on video 20161005_no9_4\n",
      "predicting frame 500 on video 20161005_no9_4\n",
      "predicting frame 1000 on video 20161005_no9_4\n",
      "predicting frame 1500 on video 20161005_no9_4\n",
      "predicting frame 2000 on video 20161005_no9_4\n",
      "predicting frame 2500 on video 20161005_no9_4\n",
      "predicting frame 3000 on video 20161005_no9_4\n",
      "predicting frame 3500 on video 20161005_no9_4\n",
      "2 20\n",
      "predicting frame 0 on video 20150807_no8B_1\n",
      "predicting frame 500 on video 20150807_no8B_1\n",
      "predicting frame 1000 on video 20150807_no8B_1\n",
      "predicting frame 1500 on video 20150807_no8B_1\n",
      "predicting frame 2000 on video 20150807_no8B_1\n",
      "predicting frame 2500 on video 20150807_no8B_1\n",
      "predicting frame 3000 on video 20150807_no8B_1\n",
      "predicting frame 0 on video 20150820_no8B_2\n",
      "predicting frame 500 on video 20150820_no8B_2\n",
      "predicting frame 0 on video 20150820_no8B_3\n",
      "predicting frame 500 on video 20150820_no8B_3\n",
      "predicting frame 1000 on video 20150820_no8B_3\n",
      "predicting frame 1500 on video 20150820_no8B_3\n",
      "predicting frame 2000 on video 20150820_no8B_3\n",
      "predicting frame 2500 on video 20150820_no8B_3\n",
      "predicting frame 3000 on video 20150820_no8B_3\n",
      "predicting frame 0 on video 20150827_no8B_1\n",
      "predicting frame 500 on video 20150827_no8B_1\n",
      "predicting frame 1000 on video 20150827_no8B_1\n",
      "predicting frame 1500 on video 20150827_no8B_1\n",
      "predicting frame 2000 on video 20150827_no8B_1\n",
      "predicting frame 2500 on video 20150827_no8B_1\n",
      "predicting frame 3000 on video 20150827_no8B_1\n",
      "predicting frame 3500 on video 20150827_no8B_1\n",
      "predicting frame 0 on video 20150827_no8B_3\n",
      "predicting frame 500 on video 20150827_no8B_3\n",
      "predicting frame 1000 on video 20150827_no8B_3\n",
      "predicting frame 1500 on video 20150827_no8B_3\n",
      "predicting frame 2000 on video 20150827_no8B_3\n",
      "predicting frame 2500 on video 20150827_no8B_3\n",
      "predicting frame 3000 on video 20150827_no8B_3\n",
      "predicting frame 0 on video 20160801_no9_2\n",
      "predicting frame 500 on video 20160801_no9_2\n",
      "predicting frame 1000 on video 20160801_no9_2\n",
      "predicting frame 1500 on video 20160801_no9_2\n",
      "predicting frame 2000 on video 20160801_no9_2\n",
      "predicting frame 2500 on video 20160801_no9_2\n",
      "predicting frame 3000 on video 20160801_no9_2\n",
      "predicting frame 3500 on video 20160801_no9_2\n",
      "predicting frame 0 on video 20160812_no9_1\n",
      "predicting frame 500 on video 20160812_no9_1\n",
      "predicting frame 1000 on video 20160812_no9_1\n",
      "predicting frame 1500 on video 20160812_no9_1\n",
      "predicting frame 2000 on video 20160812_no9_1\n",
      "predicting frame 2500 on video 20160812_no9_1\n",
      "predicting frame 3000 on video 20160812_no9_1\n",
      "predicting frame 3500 on video 20160812_no9_1\n",
      "predicting frame 0 on video 20160812_no9_2\n",
      "predicting frame 500 on video 20160812_no9_2\n",
      "predicting frame 0 on video 20160812_no9_3\n",
      "predicting frame 500 on video 20160812_no9_3\n",
      "predicting frame 1000 on video 20160812_no9_3\n",
      "predicting frame 1500 on video 20160812_no9_3\n",
      "predicting frame 2000 on video 20160812_no9_3\n",
      "predicting frame 2500 on video 20160812_no9_3\n",
      "predicting frame 3000 on video 20160812_no9_3\n",
      "predicting frame 3500 on video 20160812_no9_3\n",
      "predicting frame 0 on video 20160819_no9_1\n",
      "predicting frame 500 on video 20160819_no9_1\n",
      "predicting frame 1000 on video 20160819_no9_1\n",
      "predicting frame 1500 on video 20160819_no9_1\n",
      "predicting frame 2000 on video 20160819_no9_1\n",
      "predicting frame 2500 on video 20160819_no9_1\n",
      "predicting frame 3000 on video 20160819_no9_1\n",
      "predicting frame 3500 on video 20160819_no9_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting frame 0 on video 20160819_no9_3\n",
      "predicting frame 500 on video 20160819_no9_3\n",
      "predicting frame 1000 on video 20160819_no9_3\n",
      "predicting frame 1500 on video 20160819_no9_3\n",
      "predicting frame 2000 on video 20160819_no9_3\n",
      "predicting frame 2500 on video 20160819_no9_3\n",
      "predicting frame 3000 on video 20160819_no9_3\n",
      "predicting frame 3500 on video 20160819_no9_3\n",
      "predicting frame 0 on video 20160819_no9_4\n",
      "predicting frame 500 on video 20160819_no9_4\n",
      "predicting frame 1000 on video 20160819_no9_4\n",
      "predicting frame 1500 on video 20160819_no9_4\n",
      "predicting frame 2000 on video 20160819_no9_4\n",
      "predicting frame 2500 on video 20160819_no9_4\n",
      "predicting frame 3000 on video 20160819_no9_4\n",
      "predicting frame 3500 on video 20160819_no9_4\n",
      "predicting frame 0 on video 20160930_no8_1\n",
      "predicting frame 500 on video 20160930_no8_1\n",
      "predicting frame 1000 on video 20160930_no8_1\n",
      "predicting frame 1500 on video 20160930_no8_1\n",
      "predicting frame 2000 on video 20160930_no8_1\n",
      "predicting frame 2500 on video 20160930_no8_1\n",
      "predicting frame 0 on video 20160930_no8_3\n",
      "predicting frame 500 on video 20160930_no8_3\n",
      "predicting frame 1000 on video 20160930_no8_3\n",
      "predicting frame 1500 on video 20160930_no8_3\n",
      "predicting frame 2000 on video 20160930_no8_3\n",
      "predicting frame 2500 on video 20160930_no8_3\n",
      "predicting frame 3000 on video 20160930_no8_3\n",
      "predicting frame 3500 on video 20160930_no8_3\n",
      "predicting frame 0 on video 20160930_no8_4\n",
      "predicting frame 500 on video 20160930_no8_4\n",
      "predicting frame 1000 on video 20160930_no8_4\n",
      "predicting frame 1500 on video 20160930_no8_4\n",
      "predicting frame 2000 on video 20160930_no8_4\n",
      "predicting frame 2500 on video 20160930_no8_4\n",
      "predicting frame 0 on video 20161005_no9_2\n",
      "predicting frame 500 on video 20161005_no9_2\n",
      "predicting frame 0 on video 20161005_no9_3\n",
      "predicting frame 500 on video 20161005_no9_3\n",
      "predicting frame 1000 on video 20161005_no9_3\n",
      "predicting frame 1500 on video 20161005_no9_3\n",
      "predicting frame 2000 on video 20161005_no9_3\n",
      "predicting frame 2500 on video 20161005_no9_3\n",
      "predicting frame 3000 on video 20161005_no9_3\n",
      "predicting frame 3500 on video 20161005_no9_3\n",
      "predicting frame 0 on video 20161005_no9_4\n",
      "predicting frame 500 on video 20161005_no9_4\n",
      "predicting frame 1000 on video 20161005_no9_4\n",
      "predicting frame 1500 on video 20161005_no9_4\n",
      "predicting frame 2000 on video 20161005_no9_4\n",
      "predicting frame 2500 on video 20161005_no9_4\n",
      "predicting frame 3000 on video 20161005_no9_4\n",
      "predicting frame 3500 on video 20161005_no9_4\n",
      "3 10\n",
      "predicting frame 0 on video 20150807_no8B_1\n",
      "predicting frame 500 on video 20150807_no8B_1\n",
      "predicting frame 1000 on video 20150807_no8B_1\n",
      "predicting frame 1500 on video 20150807_no8B_1\n",
      "predicting frame 2000 on video 20150807_no8B_1\n",
      "predicting frame 2500 on video 20150807_no8B_1\n",
      "predicting frame 3000 on video 20150807_no8B_1\n",
      "predicting frame 0 on video 20150820_no8B_2\n",
      "predicting frame 500 on video 20150820_no8B_2\n",
      "predicting frame 0 on video 20150820_no8B_3\n",
      "predicting frame 500 on video 20150820_no8B_3\n",
      "predicting frame 1000 on video 20150820_no8B_3\n",
      "predicting frame 1500 on video 20150820_no8B_3\n",
      "predicting frame 2000 on video 20150820_no8B_3\n",
      "predicting frame 2500 on video 20150820_no8B_3\n",
      "predicting frame 3000 on video 20150820_no8B_3\n",
      "predicting frame 0 on video 20150827_no8B_1\n",
      "predicting frame 500 on video 20150827_no8B_1\n",
      "predicting frame 1000 on video 20150827_no8B_1\n",
      "predicting frame 1500 on video 20150827_no8B_1\n",
      "predicting frame 2000 on video 20150827_no8B_1\n",
      "predicting frame 2500 on video 20150827_no8B_1\n",
      "predicting frame 3000 on video 20150827_no8B_1\n",
      "predicting frame 3500 on video 20150827_no8B_1\n",
      "predicting frame 0 on video 20150827_no8B_3\n",
      "predicting frame 500 on video 20150827_no8B_3\n",
      "predicting frame 1000 on video 20150827_no8B_3\n",
      "predicting frame 1500 on video 20150827_no8B_3\n",
      "predicting frame 2000 on video 20150827_no8B_3\n",
      "predicting frame 2500 on video 20150827_no8B_3\n",
      "predicting frame 3000 on video 20150827_no8B_3\n",
      "predicting frame 0 on video 20160801_no9_2\n",
      "predicting frame 500 on video 20160801_no9_2\n",
      "predicting frame 1000 on video 20160801_no9_2\n",
      "predicting frame 1500 on video 20160801_no9_2\n",
      "predicting frame 2000 on video 20160801_no9_2\n",
      "predicting frame 2500 on video 20160801_no9_2\n",
      "predicting frame 3000 on video 20160801_no9_2\n",
      "predicting frame 3500 on video 20160801_no9_2\n",
      "predicting frame 0 on video 20160812_no9_1\n",
      "predicting frame 500 on video 20160812_no9_1\n",
      "predicting frame 1000 on video 20160812_no9_1\n",
      "predicting frame 1500 on video 20160812_no9_1\n",
      "predicting frame 2000 on video 20160812_no9_1\n",
      "predicting frame 2500 on video 20160812_no9_1\n",
      "predicting frame 3000 on video 20160812_no9_1\n",
      "predicting frame 3500 on video 20160812_no9_1\n",
      "predicting frame 0 on video 20160812_no9_2\n",
      "predicting frame 500 on video 20160812_no9_2\n",
      "predicting frame 0 on video 20160812_no9_3\n",
      "predicting frame 500 on video 20160812_no9_3\n",
      "predicting frame 1000 on video 20160812_no9_3\n",
      "predicting frame 1500 on video 20160812_no9_3\n",
      "predicting frame 2000 on video 20160812_no9_3\n",
      "predicting frame 2500 on video 20160812_no9_3\n",
      "predicting frame 3000 on video 20160812_no9_3\n",
      "predicting frame 3500 on video 20160812_no9_3\n",
      "predicting frame 0 on video 20160819_no9_1\n",
      "predicting frame 500 on video 20160819_no9_1\n",
      "predicting frame 1000 on video 20160819_no9_1\n",
      "predicting frame 1500 on video 20160819_no9_1\n",
      "predicting frame 2000 on video 20160819_no9_1\n",
      "predicting frame 2500 on video 20160819_no9_1\n",
      "predicting frame 3000 on video 20160819_no9_1\n",
      "predicting frame 3500 on video 20160819_no9_1\n",
      "predicting frame 0 on video 20160819_no9_3\n",
      "predicting frame 500 on video 20160819_no9_3\n",
      "predicting frame 1000 on video 20160819_no9_3\n",
      "predicting frame 1500 on video 20160819_no9_3\n",
      "predicting frame 2000 on video 20160819_no9_3\n",
      "predicting frame 2500 on video 20160819_no9_3\n",
      "predicting frame 3000 on video 20160819_no9_3\n",
      "predicting frame 3500 on video 20160819_no9_3\n",
      "predicting frame 0 on video 20160819_no9_4\n",
      "predicting frame 500 on video 20160819_no9_4\n",
      "predicting frame 1000 on video 20160819_no9_4\n",
      "predicting frame 1500 on video 20160819_no9_4\n",
      "predicting frame 2000 on video 20160819_no9_4\n",
      "predicting frame 2500 on video 20160819_no9_4\n",
      "predicting frame 3000 on video 20160819_no9_4\n",
      "predicting frame 3500 on video 20160819_no9_4\n",
      "predicting frame 0 on video 20160930_no8_1\n",
      "predicting frame 500 on video 20160930_no8_1\n",
      "predicting frame 1000 on video 20160930_no8_1\n",
      "predicting frame 1500 on video 20160930_no8_1\n",
      "predicting frame 2000 on video 20160930_no8_1\n",
      "predicting frame 2500 on video 20160930_no8_1\n",
      "predicting frame 0 on video 20160930_no8_3\n",
      "predicting frame 500 on video 20160930_no8_3\n",
      "predicting frame 1000 on video 20160930_no8_3\n",
      "predicting frame 1500 on video 20160930_no8_3\n",
      "predicting frame 2000 on video 20160930_no8_3\n",
      "predicting frame 2500 on video 20160930_no8_3\n",
      "predicting frame 3000 on video 20160930_no8_3\n",
      "predicting frame 3500 on video 20160930_no8_3\n",
      "predicting frame 0 on video 20160930_no8_4\n",
      "predicting frame 500 on video 20160930_no8_4\n",
      "predicting frame 1000 on video 20160930_no8_4\n",
      "predicting frame 1500 on video 20160930_no8_4\n",
      "predicting frame 2000 on video 20160930_no8_4\n",
      "predicting frame 2500 on video 20160930_no8_4\n",
      "predicting frame 0 on video 20161005_no9_2\n",
      "predicting frame 500 on video 20161005_no9_2\n",
      "predicting frame 0 on video 20161005_no9_3\n",
      "predicting frame 500 on video 20161005_no9_3\n",
      "predicting frame 1000 on video 20161005_no9_3\n",
      "predicting frame 1500 on video 20161005_no9_3\n",
      "predicting frame 2000 on video 20161005_no9_3\n",
      "predicting frame 2500 on video 20161005_no9_3\n",
      "predicting frame 3000 on video 20161005_no9_3\n",
      "predicting frame 3500 on video 20161005_no9_3\n",
      "predicting frame 0 on video 20161005_no9_4\n",
      "predicting frame 500 on video 20161005_no9_4\n",
      "predicting frame 1000 on video 20161005_no9_4\n",
      "predicting frame 1500 on video 20161005_no9_4\n",
      "predicting frame 2000 on video 20161005_no9_4\n",
      "predicting frame 2500 on video 20161005_no9_4\n",
      "predicting frame 3000 on video 20161005_no9_4\n",
      "predicting frame 3500 on video 20161005_no9_4\n",
      "4 20\n",
      "predicting frame 0 on video 20150807_no8B_1\n",
      "predicting frame 500 on video 20150807_no8B_1\n",
      "predicting frame 1000 on video 20150807_no8B_1\n",
      "predicting frame 1500 on video 20150807_no8B_1\n",
      "predicting frame 2000 on video 20150807_no8B_1\n",
      "predicting frame 2500 on video 20150807_no8B_1\n",
      "predicting frame 3000 on video 20150807_no8B_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting frame 0 on video 20150820_no8B_2\n",
      "predicting frame 500 on video 20150820_no8B_2\n",
      "predicting frame 0 on video 20150820_no8B_3\n",
      "predicting frame 500 on video 20150820_no8B_3\n",
      "predicting frame 1000 on video 20150820_no8B_3\n",
      "predicting frame 1500 on video 20150820_no8B_3\n",
      "predicting frame 2000 on video 20150820_no8B_3\n",
      "predicting frame 2500 on video 20150820_no8B_3\n",
      "predicting frame 3000 on video 20150820_no8B_3\n",
      "predicting frame 0 on video 20150827_no8B_1\n",
      "predicting frame 500 on video 20150827_no8B_1\n",
      "predicting frame 1000 on video 20150827_no8B_1\n",
      "predicting frame 1500 on video 20150827_no8B_1\n",
      "predicting frame 2000 on video 20150827_no8B_1\n",
      "predicting frame 2500 on video 20150827_no8B_1\n",
      "predicting frame 3000 on video 20150827_no8B_1\n",
      "predicting frame 3500 on video 20150827_no8B_1\n",
      "predicting frame 0 on video 20150827_no8B_3\n",
      "predicting frame 500 on video 20150827_no8B_3\n",
      "predicting frame 1000 on video 20150827_no8B_3\n",
      "predicting frame 1500 on video 20150827_no8B_3\n",
      "predicting frame 2000 on video 20150827_no8B_3\n",
      "predicting frame 2500 on video 20150827_no8B_3\n",
      "predicting frame 3000 on video 20150827_no8B_3\n",
      "predicting frame 0 on video 20160801_no9_2\n",
      "predicting frame 500 on video 20160801_no9_2\n",
      "predicting frame 1000 on video 20160801_no9_2\n",
      "predicting frame 1500 on video 20160801_no9_2\n",
      "predicting frame 2000 on video 20160801_no9_2\n",
      "predicting frame 2500 on video 20160801_no9_2\n",
      "predicting frame 3000 on video 20160801_no9_2\n",
      "predicting frame 3500 on video 20160801_no9_2\n",
      "predicting frame 0 on video 20160812_no9_1\n",
      "predicting frame 500 on video 20160812_no9_1\n",
      "predicting frame 1000 on video 20160812_no9_1\n",
      "predicting frame 1500 on video 20160812_no9_1\n",
      "predicting frame 2000 on video 20160812_no9_1\n",
      "predicting frame 2500 on video 20160812_no9_1\n",
      "predicting frame 3000 on video 20160812_no9_1\n",
      "predicting frame 3500 on video 20160812_no9_1\n",
      "predicting frame 0 on video 20160812_no9_2\n",
      "predicting frame 500 on video 20160812_no9_2\n",
      "predicting frame 0 on video 20160812_no9_3\n",
      "predicting frame 500 on video 20160812_no9_3\n",
      "predicting frame 1000 on video 20160812_no9_3\n",
      "predicting frame 1500 on video 20160812_no9_3\n",
      "predicting frame 2000 on video 20160812_no9_3\n",
      "predicting frame 2500 on video 20160812_no9_3\n",
      "predicting frame 3000 on video 20160812_no9_3\n",
      "predicting frame 3500 on video 20160812_no9_3\n",
      "predicting frame 0 on video 20160819_no9_1\n",
      "predicting frame 500 on video 20160819_no9_1\n",
      "predicting frame 1000 on video 20160819_no9_1\n",
      "predicting frame 1500 on video 20160819_no9_1\n",
      "predicting frame 2000 on video 20160819_no9_1\n",
      "predicting frame 2500 on video 20160819_no9_1\n",
      "predicting frame 3000 on video 20160819_no9_1\n",
      "predicting frame 3500 on video 20160819_no9_1\n",
      "predicting frame 0 on video 20160819_no9_3\n",
      "predicting frame 500 on video 20160819_no9_3\n",
      "predicting frame 1000 on video 20160819_no9_3\n",
      "predicting frame 1500 on video 20160819_no9_3\n",
      "predicting frame 2000 on video 20160819_no9_3\n",
      "predicting frame 2500 on video 20160819_no9_3\n",
      "predicting frame 3000 on video 20160819_no9_3\n",
      "predicting frame 3500 on video 20160819_no9_3\n",
      "predicting frame 0 on video 20160819_no9_4\n",
      "predicting frame 500 on video 20160819_no9_4\n",
      "predicting frame 1000 on video 20160819_no9_4\n",
      "predicting frame 1500 on video 20160819_no9_4\n",
      "predicting frame 2000 on video 20160819_no9_4\n",
      "predicting frame 2500 on video 20160819_no9_4\n",
      "predicting frame 3000 on video 20160819_no9_4\n",
      "predicting frame 3500 on video 20160819_no9_4\n",
      "predicting frame 0 on video 20160930_no8_1\n",
      "predicting frame 500 on video 20160930_no8_1\n",
      "predicting frame 1000 on video 20160930_no8_1\n",
      "predicting frame 1500 on video 20160930_no8_1\n",
      "predicting frame 2000 on video 20160930_no8_1\n",
      "predicting frame 2500 on video 20160930_no8_1\n",
      "predicting frame 0 on video 20160930_no8_3\n",
      "predicting frame 500 on video 20160930_no8_3\n",
      "predicting frame 1000 on video 20160930_no8_3\n",
      "predicting frame 1500 on video 20160930_no8_3\n",
      "predicting frame 2000 on video 20160930_no8_3\n",
      "predicting frame 2500 on video 20160930_no8_3\n",
      "predicting frame 3000 on video 20160930_no8_3\n",
      "predicting frame 3500 on video 20160930_no8_3\n",
      "predicting frame 0 on video 20160930_no8_4\n",
      "predicting frame 500 on video 20160930_no8_4\n",
      "predicting frame 1000 on video 20160930_no8_4\n",
      "predicting frame 1500 on video 20160930_no8_4\n",
      "predicting frame 2000 on video 20160930_no8_4\n",
      "predicting frame 2500 on video 20160930_no8_4\n",
      "predicting frame 0 on video 20161005_no9_2\n",
      "predicting frame 500 on video 20161005_no9_2\n",
      "predicting frame 0 on video 20161005_no9_3\n",
      "predicting frame 500 on video 20161005_no9_3\n",
      "predicting frame 1000 on video 20161005_no9_3\n",
      "predicting frame 1500 on video 20161005_no9_3\n",
      "predicting frame 2000 on video 20161005_no9_3\n",
      "predicting frame 2500 on video 20161005_no9_3\n",
      "predicting frame 3000 on video 20161005_no9_3\n",
      "predicting frame 3500 on video 20161005_no9_3\n",
      "predicting frame 0 on video 20161005_no9_4\n",
      "predicting frame 500 on video 20161005_no9_4\n",
      "predicting frame 1000 on video 20161005_no9_4\n",
      "predicting frame 1500 on video 20161005_no9_4\n",
      "predicting frame 2000 on video 20161005_no9_4\n",
      "predicting frame 2500 on video 20161005_no9_4\n",
      "predicting frame 3000 on video 20161005_no9_4\n",
      "predicting frame 3500 on video 20161005_no9_4\n",
      "5 10\n",
      "predicting frame 0 on video 20150807_no8B_1\n",
      "predicting frame 500 on video 20150807_no8B_1\n",
      "predicting frame 1000 on video 20150807_no8B_1\n",
      "predicting frame 1500 on video 20150807_no8B_1\n",
      "predicting frame 2000 on video 20150807_no8B_1\n",
      "predicting frame 2500 on video 20150807_no8B_1\n",
      "predicting frame 3000 on video 20150807_no8B_1\n",
      "predicting frame 0 on video 20150820_no8B_2\n",
      "predicting frame 500 on video 20150820_no8B_2\n",
      "predicting frame 0 on video 20150820_no8B_3\n",
      "predicting frame 500 on video 20150820_no8B_3\n",
      "predicting frame 1000 on video 20150820_no8B_3\n",
      "predicting frame 1500 on video 20150820_no8B_3\n",
      "predicting frame 2000 on video 20150820_no8B_3\n",
      "predicting frame 2500 on video 20150820_no8B_3\n",
      "predicting frame 3000 on video 20150820_no8B_3\n",
      "predicting frame 0 on video 20150827_no8B_1\n",
      "predicting frame 500 on video 20150827_no8B_1\n",
      "predicting frame 1000 on video 20150827_no8B_1\n",
      "predicting frame 1500 on video 20150827_no8B_1\n",
      "predicting frame 2000 on video 20150827_no8B_1\n",
      "predicting frame 2500 on video 20150827_no8B_1\n",
      "predicting frame 3000 on video 20150827_no8B_1\n",
      "predicting frame 3500 on video 20150827_no8B_1\n",
      "predicting frame 0 on video 20150827_no8B_3\n",
      "predicting frame 500 on video 20150827_no8B_3\n",
      "predicting frame 1000 on video 20150827_no8B_3\n",
      "predicting frame 1500 on video 20150827_no8B_3\n",
      "predicting frame 2000 on video 20150827_no8B_3\n",
      "predicting frame 2500 on video 20150827_no8B_3\n",
      "predicting frame 3000 on video 20150827_no8B_3\n",
      "predicting frame 0 on video 20160801_no9_2\n",
      "predicting frame 500 on video 20160801_no9_2\n",
      "predicting frame 1000 on video 20160801_no9_2\n",
      "predicting frame 1500 on video 20160801_no9_2\n",
      "predicting frame 2000 on video 20160801_no9_2\n",
      "predicting frame 2500 on video 20160801_no9_2\n",
      "predicting frame 3000 on video 20160801_no9_2\n",
      "predicting frame 3500 on video 20160801_no9_2\n",
      "predicting frame 0 on video 20160812_no9_1\n",
      "predicting frame 500 on video 20160812_no9_1\n",
      "predicting frame 1000 on video 20160812_no9_1\n",
      "predicting frame 1500 on video 20160812_no9_1\n",
      "predicting frame 2000 on video 20160812_no9_1\n",
      "predicting frame 2500 on video 20160812_no9_1\n",
      "predicting frame 3000 on video 20160812_no9_1\n",
      "predicting frame 3500 on video 20160812_no9_1\n",
      "predicting frame 0 on video 20160812_no9_2\n",
      "predicting frame 500 on video 20160812_no9_2\n",
      "predicting frame 0 on video 20160812_no9_3\n",
      "predicting frame 500 on video 20160812_no9_3\n",
      "predicting frame 1000 on video 20160812_no9_3\n",
      "predicting frame 1500 on video 20160812_no9_3\n",
      "predicting frame 2000 on video 20160812_no9_3\n",
      "predicting frame 2500 on video 20160812_no9_3\n",
      "predicting frame 3000 on video 20160812_no9_3\n",
      "predicting frame 3500 on video 20160812_no9_3\n",
      "predicting frame 0 on video 20160819_no9_1\n",
      "predicting frame 500 on video 20160819_no9_1\n",
      "predicting frame 1000 on video 20160819_no9_1\n",
      "predicting frame 1500 on video 20160819_no9_1\n",
      "predicting frame 2000 on video 20160819_no9_1\n",
      "predicting frame 2500 on video 20160819_no9_1\n",
      "predicting frame 3000 on video 20160819_no9_1\n",
      "predicting frame 3500 on video 20160819_no9_1\n",
      "predicting frame 0 on video 20160819_no9_3\n",
      "predicting frame 500 on video 20160819_no9_3\n",
      "predicting frame 1000 on video 20160819_no9_3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting frame 1500 on video 20160819_no9_3\n",
      "predicting frame 2000 on video 20160819_no9_3\n",
      "predicting frame 2500 on video 20160819_no9_3\n",
      "predicting frame 3000 on video 20160819_no9_3\n",
      "predicting frame 3500 on video 20160819_no9_3\n",
      "predicting frame 0 on video 20160819_no9_4\n",
      "predicting frame 500 on video 20160819_no9_4\n",
      "predicting frame 1000 on video 20160819_no9_4\n",
      "predicting frame 1500 on video 20160819_no9_4\n",
      "predicting frame 2000 on video 20160819_no9_4\n",
      "predicting frame 2500 on video 20160819_no9_4\n",
      "predicting frame 3000 on video 20160819_no9_4\n",
      "predicting frame 3500 on video 20160819_no9_4\n",
      "predicting frame 0 on video 20160930_no8_1\n",
      "predicting frame 500 on video 20160930_no8_1\n",
      "predicting frame 1000 on video 20160930_no8_1\n",
      "predicting frame 1500 on video 20160930_no8_1\n",
      "predicting frame 2000 on video 20160930_no8_1\n",
      "predicting frame 2500 on video 20160930_no8_1\n",
      "predicting frame 0 on video 20160930_no8_3\n",
      "predicting frame 500 on video 20160930_no8_3\n",
      "predicting frame 1000 on video 20160930_no8_3\n",
      "predicting frame 1500 on video 20160930_no8_3\n",
      "predicting frame 2000 on video 20160930_no8_3\n",
      "predicting frame 2500 on video 20160930_no8_3\n",
      "predicting frame 3000 on video 20160930_no8_3\n",
      "predicting frame 3500 on video 20160930_no8_3\n",
      "predicting frame 0 on video 20160930_no8_4\n",
      "predicting frame 500 on video 20160930_no8_4\n",
      "predicting frame 1000 on video 20160930_no8_4\n",
      "predicting frame 1500 on video 20160930_no8_4\n",
      "predicting frame 2000 on video 20160930_no8_4\n",
      "predicting frame 2500 on video 20160930_no8_4\n",
      "predicting frame 0 on video 20161005_no9_2\n",
      "predicting frame 500 on video 20161005_no9_2\n",
      "predicting frame 0 on video 20161005_no9_3\n",
      "predicting frame 500 on video 20161005_no9_3\n",
      "predicting frame 1000 on video 20161005_no9_3\n",
      "predicting frame 1500 on video 20161005_no9_3\n",
      "predicting frame 2000 on video 20161005_no9_3\n",
      "predicting frame 2500 on video 20161005_no9_3\n",
      "predicting frame 3000 on video 20161005_no9_3\n",
      "predicting frame 3500 on video 20161005_no9_3\n",
      "predicting frame 0 on video 20161005_no9_4\n",
      "predicting frame 500 on video 20161005_no9_4\n",
      "predicting frame 1000 on video 20161005_no9_4\n",
      "predicting frame 1500 on video 20161005_no9_4\n",
      "predicting frame 2000 on video 20161005_no9_4\n",
      "predicting frame 2500 on video 20161005_no9_4\n",
      "predicting frame 3000 on video 20161005_no9_4\n",
      "predicting frame 3500 on video 20161005_no9_4\n"
     ]
    }
   ],
   "source": [
    "for experiment in experiments:\n",
    "    model_id = experiment['model_id']\n",
    "    sequence_length = experiment['sequence_length']\n",
    "    print(model_id, sequence_length)\n",
    "\n",
    "    # load model and labels\n",
    "    model = load_model(pwd + 'models/' + str(model_id) + '/model_best.h5')\n",
    "    labels = pd.read_csv(path_data + \"labels.csv\")\n",
    "    labels['idx'] = labels['frame'].str.split(\"_\").str.get(-1).str.split(\".\").str.get(0).astype(int)\n",
    "    videos = list(labels['video'].unique())\n",
    "\n",
    "    # build CSV with frame predictions and ground truth\n",
    "    fps = []\n",
    "\n",
    "    for video in videos:\n",
    "\n",
    "        # load features then construct frame blocks and predict using model\n",
    "        features = np.load(\"/mnt/seals/cache/features/vgg16/max/\" + video + '.npy') \n",
    "\n",
    "        frame_predictions = []\n",
    "        for c, feature in enumerate(features):\n",
    "            if c % 500 == 0:\n",
    "                print (\"predicting frame {} on video {}\".format(c, video))\n",
    "            if c >= sequence_length:\n",
    "                clip = features[c-sequence_length:c,:]\n",
    "                clip = np.expand_dims(clip, axis=0)\n",
    "                frame_prediction = model.predict(clip)\n",
    "                frame_predictions.append(frame_prediction)\n",
    "\n",
    "        # flatten into dataframe\n",
    "        fp = np.array(frame_predictions)\n",
    "        fp = np.squeeze(fp,axis=1)\n",
    "        fp = pd.DataFrame(fp)\n",
    "        fp.index = fp.index + sequence_length - 1\n",
    "        fp.columns = class_names\n",
    "        fp['prediction'] = fp.idxmax(axis=1)\n",
    "        labels_vid = labels[labels['video'] == video]\n",
    "        labels_vid.reset_index(inplace=True,drop=True)\n",
    "        fp = pd.merge(fp, labels_vid, left_index=True,right_index=True,how='left')\n",
    "        fps.append(fp)\n",
    "\n",
    "    # output\n",
    "    df = pd.concat(fps)\n",
    "    df['error'] = (df['prediction'] != df['label']).astype(int)\n",
    "    df.to_csv(pwd + 'models/' + str(model_id) + '/frame_predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## image only model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T06:38:30.446514Z",
     "start_time": "2020-03-24T06:38:30.442094Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'architecture': 'image_mlp_frozen',\n",
       " 'dropout': 0.2,\n",
       " 'layer_1_size': 128,\n",
       " 'layer_2_size': 256,\n",
       " 'layer_3_size': 256,\n",
       " 'model_id': 6,\n",
       " 'pooling': 'max',\n",
       " 'pretrained_model_name': 'resnet50',\n",
       " 'sequence_length': 1,\n",
       " 'sequence_model': '',\n",
       " 'sequence_model_layers': ''}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment = experiment6\n",
    "experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T06:38:32.869807Z",
     "start_time": "2020-03-24T06:38:31.035303Z"
    }
   },
   "outputs": [],
   "source": [
    "model_id = experiment['model_id']\n",
    "\n",
    "# load model and labels\n",
    "model = load_model(pwd + 'models/' + str(model_id) + '/model_best.h5')\n",
    "labels = pd.read_csv(path_data + \"labels.csv\")\n",
    "labels['idx'] = labels['frame'].str.split(\"_\").str.get(-1).str.split(\".\").str.get(0).astype(int)\n",
    "videos = list(labels['video'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T06:39:20.715064Z",
     "start_time": "2020-03-24T06:38:32.872165Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XXX 20150807_no8B_1 3139\n",
      "XXX 20150820_no8B_2 570\n",
      "XXX 20150820_no8B_3 3407\n",
      "XXX 20150827_no8B_1 3600\n",
      "XXX 20150827_no8B_3 3241\n",
      "XXX 20160801_no9_2 3600\n",
      "XXX 20160812_no9_1 3600\n",
      "XXX 20160812_no9_2 563\n",
      "XXX 20160812_no9_3 3600\n",
      "XXX 20160819_no9_1 3600\n",
      "XXX 20160819_no9_3 3600\n",
      "XXX 20160819_no9_4 3600\n",
      "XXX 20160930_no8_1 2721\n",
      "XXX 20160930_no8_3 3600\n",
      "XXX 20160930_no8_4 2816\n",
      "XXX 20161005_no9_2 560\n",
      "XXX 20161005_no9_3 3600\n",
      "XXX 20161005_no9_4 3600\n"
     ]
    }
   ],
   "source": [
    "# build CSV with frame predictions and ground truth\n",
    "fps = []\n",
    "\n",
    "for video in videos:\n",
    "\n",
    "    # load features then construct frame blocks and predict using model\n",
    "    features = np.load(\"/mnt/seals/cache/features/resnet50/max/\" + video + '.npy') \n",
    "\n",
    "    frame_predictions = []\n",
    "    for c, feature in enumerate(features):\n",
    "#         if c % 500 == 0:\n",
    "#             print (\"predicting frame {} on video {}\".format(c, video))\n",
    "        frame_prediction = model.predict(np.expand_dims(feature, axis=0))\n",
    "        frame_predictions.append(frame_prediction)\n",
    "\n",
    "    # flatten into dataframe\n",
    "    fp = np.array(frame_predictions)\n",
    "    fp = np.squeeze(fp,axis=1)\n",
    "    fp = pd.DataFrame(fp)\n",
    "    fp.columns = class_names\n",
    "    fp['prediction'] = fp.idxmax(axis=1)\n",
    "    labels_vid = labels[labels['video'] == video]\n",
    "    labels_vid.reset_index(inplace=True,drop=True)\n",
    "    fp = pd.merge(fp, labels_vid, left_index=True,right_index=True,how='left')\n",
    "    fps.append(fp)\n",
    "    print(\"XXX\", video, len(fp))\n",
    "\n",
    "# output\n",
    "df = pd.concat(fps)\n",
    "df['error'] = (df['prediction'] != df['label']).astype(int)\n",
    "df.to_csv(pwd + 'models/' + str(model_id) + '/frame_predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## concat model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T09:23:42.337626Z",
     "start_time": "2020-03-23T09:23:42.333069Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'architecture': 'video_mlp_concat',\n",
       " 'dropout': 0.2,\n",
       " 'layer_1_size': 128,\n",
       " 'layer_2_size': 128,\n",
       " 'layer_3_size': 128,\n",
       " 'model_id': 7,\n",
       " 'pooling': 'max',\n",
       " 'pretrained_model_name': 'resnet50',\n",
       " 'sequence_length': 3,\n",
       " 'sequence_model': '',\n",
       " 'sequence_model_layers': ''}"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment = experiment7\n",
    "experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T09:29:06.330265Z",
     "start_time": "2020-03-23T09:28:27.318236Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 3\n"
     ]
    }
   ],
   "source": [
    "model_id = experiment['model_id']\n",
    "sequence_length = experiment['sequence_length']\n",
    "print(model_id, sequence_length)\n",
    "\n",
    "# load model and labels\n",
    "model = load_model(pwd + 'models/' + str(model_id) + '/model_best.h5')\n",
    "labels = pd.read_csv(path_data + \"labels.csv\")\n",
    "labels['idx'] = labels['frame'].str.split(\"_\").str.get(-1).str.split(\".\").str.get(0).astype(int)\n",
    "videos = list(labels['video'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T09:41:55.331283Z",
     "start_time": "2020-03-23T09:37:56.186016Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting frame 0 on video 20150807_no8B_1\n",
      "predicting frame 500 on video 20150807_no8B_1\n",
      "predicting frame 1000 on video 20150807_no8B_1\n",
      "predicting frame 1500 on video 20150807_no8B_1\n",
      "predicting frame 2000 on video 20150807_no8B_1\n",
      "predicting frame 2500 on video 20150807_no8B_1\n",
      "predicting frame 3000 on video 20150807_no8B_1\n",
      "predicting frame 0 on video 20150820_no8B_2\n",
      "predicting frame 500 on video 20150820_no8B_2\n",
      "predicting frame 0 on video 20150820_no8B_3\n",
      "predicting frame 500 on video 20150820_no8B_3\n",
      "predicting frame 1000 on video 20150820_no8B_3\n",
      "predicting frame 1500 on video 20150820_no8B_3\n",
      "predicting frame 2000 on video 20150820_no8B_3\n",
      "predicting frame 2500 on video 20150820_no8B_3\n",
      "predicting frame 3000 on video 20150820_no8B_3\n",
      "predicting frame 0 on video 20150827_no8B_1\n",
      "predicting frame 500 on video 20150827_no8B_1\n",
      "predicting frame 1000 on video 20150827_no8B_1\n",
      "predicting frame 1500 on video 20150827_no8B_1\n",
      "predicting frame 2000 on video 20150827_no8B_1\n",
      "predicting frame 2500 on video 20150827_no8B_1\n",
      "predicting frame 3000 on video 20150827_no8B_1\n",
      "predicting frame 3500 on video 20150827_no8B_1\n",
      "predicting frame 0 on video 20150827_no8B_3\n",
      "predicting frame 500 on video 20150827_no8B_3\n",
      "predicting frame 1000 on video 20150827_no8B_3\n",
      "predicting frame 1500 on video 20150827_no8B_3\n",
      "predicting frame 2000 on video 20150827_no8B_3\n",
      "predicting frame 2500 on video 20150827_no8B_3\n",
      "predicting frame 3000 on video 20150827_no8B_3\n",
      "predicting frame 0 on video 20160801_no9_2\n",
      "predicting frame 500 on video 20160801_no9_2\n",
      "predicting frame 1000 on video 20160801_no9_2\n",
      "predicting frame 1500 on video 20160801_no9_2\n",
      "predicting frame 2000 on video 20160801_no9_2\n",
      "predicting frame 2500 on video 20160801_no9_2\n",
      "predicting frame 3000 on video 20160801_no9_2\n",
      "predicting frame 3500 on video 20160801_no9_2\n",
      "predicting frame 0 on video 20160812_no9_1\n",
      "predicting frame 500 on video 20160812_no9_1\n",
      "predicting frame 1000 on video 20160812_no9_1\n",
      "predicting frame 1500 on video 20160812_no9_1\n",
      "predicting frame 2000 on video 20160812_no9_1\n",
      "predicting frame 2500 on video 20160812_no9_1\n",
      "predicting frame 3000 on video 20160812_no9_1\n",
      "predicting frame 3500 on video 20160812_no9_1\n",
      "predicting frame 0 on video 20160812_no9_2\n",
      "predicting frame 500 on video 20160812_no9_2\n",
      "predicting frame 0 on video 20160812_no9_3\n",
      "predicting frame 500 on video 20160812_no9_3\n",
      "predicting frame 1000 on video 20160812_no9_3\n",
      "predicting frame 1500 on video 20160812_no9_3\n",
      "predicting frame 2000 on video 20160812_no9_3\n",
      "predicting frame 2500 on video 20160812_no9_3\n",
      "predicting frame 3000 on video 20160812_no9_3\n",
      "predicting frame 3500 on video 20160812_no9_3\n",
      "predicting frame 0 on video 20160819_no9_1\n",
      "predicting frame 500 on video 20160819_no9_1\n",
      "predicting frame 1000 on video 20160819_no9_1\n",
      "predicting frame 1500 on video 20160819_no9_1\n",
      "predicting frame 2000 on video 20160819_no9_1\n",
      "predicting frame 2500 on video 20160819_no9_1\n",
      "predicting frame 3000 on video 20160819_no9_1\n",
      "predicting frame 3500 on video 20160819_no9_1\n",
      "predicting frame 0 on video 20160819_no9_3\n",
      "predicting frame 500 on video 20160819_no9_3\n",
      "predicting frame 1000 on video 20160819_no9_3\n",
      "predicting frame 1500 on video 20160819_no9_3\n",
      "predicting frame 2000 on video 20160819_no9_3\n",
      "predicting frame 2500 on video 20160819_no9_3\n",
      "predicting frame 3000 on video 20160819_no9_3\n",
      "predicting frame 3500 on video 20160819_no9_3\n",
      "predicting frame 0 on video 20160819_no9_4\n",
      "predicting frame 500 on video 20160819_no9_4\n",
      "predicting frame 1000 on video 20160819_no9_4\n",
      "predicting frame 1500 on video 20160819_no9_4\n",
      "predicting frame 2000 on video 20160819_no9_4\n",
      "predicting frame 2500 on video 20160819_no9_4\n",
      "predicting frame 3000 on video 20160819_no9_4\n",
      "predicting frame 3500 on video 20160819_no9_4\n",
      "predicting frame 0 on video 20160930_no8_1\n",
      "predicting frame 500 on video 20160930_no8_1\n",
      "predicting frame 1000 on video 20160930_no8_1\n",
      "predicting frame 1500 on video 20160930_no8_1\n",
      "predicting frame 2000 on video 20160930_no8_1\n",
      "predicting frame 2500 on video 20160930_no8_1\n",
      "predicting frame 0 on video 20160930_no8_3\n",
      "predicting frame 500 on video 20160930_no8_3\n",
      "predicting frame 1000 on video 20160930_no8_3\n",
      "predicting frame 1500 on video 20160930_no8_3\n",
      "predicting frame 2000 on video 20160930_no8_3\n",
      "predicting frame 2500 on video 20160930_no8_3\n",
      "predicting frame 3000 on video 20160930_no8_3\n",
      "predicting frame 3500 on video 20160930_no8_3\n",
      "predicting frame 0 on video 20160930_no8_4\n",
      "predicting frame 500 on video 20160930_no8_4\n",
      "predicting frame 1000 on video 20160930_no8_4\n",
      "predicting frame 1500 on video 20160930_no8_4\n",
      "predicting frame 2000 on video 20160930_no8_4\n",
      "predicting frame 2500 on video 20160930_no8_4\n",
      "predicting frame 0 on video 20161005_no9_2\n",
      "predicting frame 500 on video 20161005_no9_2\n",
      "predicting frame 0 on video 20161005_no9_3\n",
      "predicting frame 500 on video 20161005_no9_3\n",
      "predicting frame 1000 on video 20161005_no9_3\n",
      "predicting frame 1500 on video 20161005_no9_3\n",
      "predicting frame 2000 on video 20161005_no9_3\n",
      "predicting frame 2500 on video 20161005_no9_3\n",
      "predicting frame 3000 on video 20161005_no9_3\n",
      "predicting frame 3500 on video 20161005_no9_3\n",
      "predicting frame 0 on video 20161005_no9_4\n",
      "predicting frame 500 on video 20161005_no9_4\n",
      "predicting frame 1000 on video 20161005_no9_4\n",
      "predicting frame 1500 on video 20161005_no9_4\n",
      "predicting frame 2000 on video 20161005_no9_4\n",
      "predicting frame 2500 on video 20161005_no9_4\n",
      "predicting frame 3000 on video 20161005_no9_4\n",
      "predicting frame 3500 on video 20161005_no9_4\n"
     ]
    }
   ],
   "source": [
    "# build CSV with frame predictions and ground truth\n",
    "fps = []\n",
    "\n",
    "for video in videos:\n",
    "\n",
    "    # load features then construct frame blocks and predict using model\n",
    "    features = np.load(\"/mnt/seals/cache/features/resnet50/max/\" + video + '.npy') \n",
    "\n",
    "    frame_predictions = []\n",
    "    for c, feature in enumerate(features):\n",
    "        if c % 500 == 0:\n",
    "            print (\"predicting frame {} on video {}\".format(c, video))\n",
    "        if c >= sequence_length:\n",
    "            clip = features[c-sequence_length:c,:]\n",
    "            clip = np.expand_dims(clip, axis=0)\n",
    "            frame_prediction = model.predict(clip)\n",
    "            frame_predictions.append(frame_prediction)\n",
    "\n",
    "    # flatten into dataframe\n",
    "    fp = np.array(frame_predictions)\n",
    "    fp = np.squeeze(fp,axis=1)\n",
    "    fp = pd.DataFrame(fp)\n",
    "    fp.index = fp.index + sequence_length - 1\n",
    "    fp.columns = class_names\n",
    "    fp['prediction'] = fp.idxmax(axis=1)\n",
    "    labels_vid = labels[labels['video'] == video]\n",
    "    labels_vid.reset_index(inplace=True,drop=True)\n",
    "    fp = pd.merge(fp, labels_vid, left_index=True,right_index=True,how='left')\n",
    "    fps.append(fp)\n",
    "\n",
    "# output\n",
    "df = pd.concat(fps)\n",
    "df['error'] = (df['prediction'] != df['label']).astype(int)\n",
    "df.to_csv(pwd + 'models/' + str(model_id) + '/frame_predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T06:43:27.236994Z",
     "start_time": "2020-03-24T06:43:27.233693Z"
    }
   },
   "outputs": [],
   "source": [
    "path_ship = pwd + \"ship/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T06:43:28.130114Z",
     "start_time": "2020-03-24T06:43:28.125495Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['params.json',\n",
       " 'confusion_matrix.png',\n",
       " 'model_best.h5',\n",
       " 'confusion_matrix.csv',\n",
       " 'training_round_3.log',\n",
       " 'fit_history.csv',\n",
       " 'model_config.h5',\n",
       " 'model_round_2.h5',\n",
       " 'model_summary.txt',\n",
       " 'training_round_2.log',\n",
       " 'model_round_3.h5',\n",
       " 'training_round_1.log',\n",
       " 'confusion_matrix_normalized.png',\n",
       " 'results.json',\n",
       " 'model_round_1.h5',\n",
       " 'test_predictions.npy',\n",
       " 'frame_predictions.csv']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(path_ship + '/1/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## delete models and logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T06:43:30.420764Z",
     "start_time": "2020-03-24T06:43:30.415764Z"
    }
   },
   "outputs": [],
   "source": [
    "paths = []\n",
    "for folder, subs, files in os.walk(path_ship):        \n",
    "    for filename in files:\n",
    "        if filename[-3:] == '.h5' or  filename[-4:] == '.npy' or  filename[-4:] == '.log':\n",
    "            paths.append(os.path.abspath(os.path.join(folder, filename)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T06:43:31.988592Z",
     "start_time": "2020-03-24T06:43:31.843928Z"
    }
   },
   "outputs": [],
   "source": [
    "for p in paths:\n",
    "    os.remove(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## aggregate results into csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T06:43:33.251925Z",
     "start_time": "2020-03-24T06:43:33.247663Z"
    }
   },
   "outputs": [],
   "source": [
    "paths = []\n",
    "for folder, subs, files in os.walk(path_ship):        \n",
    "    for filename in files:\n",
    "        if 'results' in filename:\n",
    "            paths.append(os.path.abspath(os.path.join(folder, filename)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T06:43:34.048634Z",
     "start_time": "2020-03-24T06:43:34.044696Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/seals/ship/3/results.json',\n",
       " '/mnt/seals/ship/2/results.json',\n",
       " '/mnt/seals/ship/1/results.json',\n",
       " '/mnt/seals/ship/5/results.json',\n",
       " '/mnt/seals/ship/6/results.json',\n",
       " '/mnt/seals/ship/4/results.json',\n",
       " '/mnt/seals/ship/7/results.json']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T06:43:36.507144Z",
     "start_time": "2020-03-24T06:43:36.504206Z"
    }
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T06:43:38.968568Z",
     "start_time": "2020-03-24T06:43:38.955943Z"
    }
   },
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for path in paths:\n",
    "    with open(path) as json_file:\n",
    "        data = json.load(json_file)\n",
    "        df = pd.DataFrame.from_dict(data, orient=\"index\").T\n",
    "        dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T06:43:39.499038Z",
     "start_time": "2020-03-24T06:43:39.493954Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.concat(dfs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T06:43:40.367387Z",
     "start_time": "2020-03-24T06:43:40.334772Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>architecture</th>\n",
       "      <th>data_total_rows_test</th>\n",
       "      <th>fit_train_loss</th>\n",
       "      <th>model_weights_path</th>\n",
       "      <th>fit_dt_train_duration_seconds</th>\n",
       "      <th>data_total_rows_valid</th>\n",
       "      <th>fit_stopped_epoch1</th>\n",
       "      <th>fit_stopped_epoch2</th>\n",
       "      <th>layer_2_size</th>\n",
       "      <th>...</th>\n",
       "      <th>fit_dt_train_start</th>\n",
       "      <th>layer_1_size</th>\n",
       "      <th>fit_stopped_epoch3</th>\n",
       "      <th>sequence_model</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>fit_train_acc</th>\n",
       "      <th>fit_val_acc</th>\n",
       "      <th>fit_dt_test_start</th>\n",
       "      <th>data_total_rows_train</th>\n",
       "      <th>fit_best_round</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>video_lrcnn_frozen</td>\n",
       "      <td>3591</td>\n",
       "      <td>0.07814</td>\n",
       "      <td>None</td>\n",
       "      <td>693</td>\n",
       "      <td>7182</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>512</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-03-22 07:09:41</td>\n",
       "      <td>256</td>\n",
       "      <td>0</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>32</td>\n",
       "      <td>0.968908</td>\n",
       "      <td>0.933982</td>\n",
       "      <td>2020-03-22 07:21:16</td>\n",
       "      <td>42082</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>video_lrcnn_frozen</td>\n",
       "      <td>3581</td>\n",
       "      <td>0.0958021</td>\n",
       "      <td>None</td>\n",
       "      <td>570</td>\n",
       "      <td>7162</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-03-22 14:21:34</td>\n",
       "      <td>256</td>\n",
       "      <td>0</td>\n",
       "      <td>SimpleRNN</td>\n",
       "      <td>32</td>\n",
       "      <td>0.962238</td>\n",
       "      <td>0.950114</td>\n",
       "      <td>2020-03-22 14:31:06</td>\n",
       "      <td>41932</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>video_lrcnn_frozen</td>\n",
       "      <td>3581</td>\n",
       "      <td>0.0569156</td>\n",
       "      <td>None</td>\n",
       "      <td>1419</td>\n",
       "      <td>7162</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>512</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-03-21 16:52:30</td>\n",
       "      <td>256</td>\n",
       "      <td>0</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>32</td>\n",
       "      <td>0.978291</td>\n",
       "      <td>0.945646</td>\n",
       "      <td>2020-03-21 17:16:10</td>\n",
       "      <td>41932</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>video_lrcnn_frozen</td>\n",
       "      <td>3591</td>\n",
       "      <td>0.119473</td>\n",
       "      <td>None</td>\n",
       "      <td>458</td>\n",
       "      <td>7182</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-03-22 14:51:17</td>\n",
       "      <td>256</td>\n",
       "      <td>0</td>\n",
       "      <td>SimpleRNN</td>\n",
       "      <td>32</td>\n",
       "      <td>0.950807</td>\n",
       "      <td>0.937801</td>\n",
       "      <td>2020-03-22 14:58:57</td>\n",
       "      <td>42082</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>image_mlp_frozen</td>\n",
       "      <td>3600</td>\n",
       "      <td>0.0913662</td>\n",
       "      <td>None</td>\n",
       "      <td>190</td>\n",
       "      <td>7200</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-03-24 06:34:12</td>\n",
       "      <td>128</td>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td>32</td>\n",
       "      <td>0.961671</td>\n",
       "      <td>0.947996</td>\n",
       "      <td>2020-03-24 06:37:23</td>\n",
       "      <td>42217</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>video_lrcnn_frozen</td>\n",
       "      <td>3581</td>\n",
       "      <td>0.104499</td>\n",
       "      <td>None</td>\n",
       "      <td>663</td>\n",
       "      <td>7162</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>512</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-03-22 07:51:47</td>\n",
       "      <td>256</td>\n",
       "      <td>0</td>\n",
       "      <td>SimpleRNN</td>\n",
       "      <td>32</td>\n",
       "      <td>0.95925</td>\n",
       "      <td>0.949495</td>\n",
       "      <td>2020-03-22 08:02:51</td>\n",
       "      <td>41932</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>video_mlp_concat</td>\n",
       "      <td>3598</td>\n",
       "      <td>0.115981</td>\n",
       "      <td>None</td>\n",
       "      <td>242</td>\n",
       "      <td>7196</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-03-22 16:14:10</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>32</td>\n",
       "      <td>0.954285</td>\n",
       "      <td>0.95166</td>\n",
       "      <td>2020-03-22 16:18:15</td>\n",
       "      <td>42187</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows  39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_id        architecture data_total_rows_test fit_train_loss  \\\n",
       "0        3  video_lrcnn_frozen                 3591        0.07814   \n",
       "0        2  video_lrcnn_frozen                 3581      0.0958021   \n",
       "0        1  video_lrcnn_frozen                 3581      0.0569156   \n",
       "0        5  video_lrcnn_frozen                 3591       0.119473   \n",
       "0        6    image_mlp_frozen                 3600      0.0913662   \n",
       "0        4  video_lrcnn_frozen                 3581       0.104499   \n",
       "0        7    video_mlp_concat                 3598       0.115981   \n",
       "\n",
       "  model_weights_path fit_dt_train_duration_seconds data_total_rows_valid  \\\n",
       "0               None                           693                  7182   \n",
       "0               None                           570                  7162   \n",
       "0               None                          1419                  7162   \n",
       "0               None                           458                  7182   \n",
       "0               None                           190                  7200   \n",
       "0               None                           663                  7162   \n",
       "0               None                           242                  7196   \n",
       "\n",
       "  fit_stopped_epoch1 fit_stopped_epoch2 layer_2_size      ...        \\\n",
       "0                  4                  0          512      ...         \n",
       "0                  4                  0          128      ...         \n",
       "0                  6                  0          512      ...         \n",
       "0                  6                  0          128      ...         \n",
       "0                  6                  4          256      ...         \n",
       "0                  6                  0          512      ...         \n",
       "0                  3                  0          128      ...         \n",
       "\n",
       "    fit_dt_train_start layer_1_size fit_stopped_epoch3 sequence_model  \\\n",
       "0  2020-03-22 07:09:41          256                  0           LSTM   \n",
       "0  2020-03-22 14:21:34          256                  0      SimpleRNN   \n",
       "0  2020-03-21 16:52:30          256                  0           LSTM   \n",
       "0  2020-03-22 14:51:17          256                  0      SimpleRNN   \n",
       "0  2020-03-24 06:34:12          128                  6                  \n",
       "0  2020-03-22 07:51:47          256                  0      SimpleRNN   \n",
       "0  2020-03-22 16:14:10          128                  0                  \n",
       "\n",
       "  batch_size fit_train_acc fit_val_acc    fit_dt_test_start  \\\n",
       "0         32      0.968908    0.933982  2020-03-22 07:21:16   \n",
       "0         32      0.962238    0.950114  2020-03-22 14:31:06   \n",
       "0         32      0.978291    0.945646  2020-03-21 17:16:10   \n",
       "0         32      0.950807    0.937801  2020-03-22 14:58:57   \n",
       "0         32      0.961671    0.947996  2020-03-24 06:37:23   \n",
       "0         32       0.95925    0.949495  2020-03-22 08:02:51   \n",
       "0         32      0.954285     0.95166  2020-03-22 16:18:15   \n",
       "\n",
       "  data_total_rows_train fit_best_round  \n",
       "0                 42082              2  \n",
       "0                 41932              2  \n",
       "0                 41932              2  \n",
       "0                 42082              2  \n",
       "0                 42217              3  \n",
       "0                 41932              3  \n",
       "0                 42187              3  \n",
       "\n",
       "[7 rows x 39 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T06:43:42.149334Z",
     "start_time": "2020-03-24T06:43:42.143893Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv(path_ship + \"results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
