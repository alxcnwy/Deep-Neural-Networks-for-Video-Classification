{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T17:39:01.973678Z",
     "start_time": "2020-03-24T17:39:01.970219Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T17:39:02.640170Z",
     "start_time": "2020-03-24T17:39:02.637521Z"
    }
   },
   "outputs": [],
   "source": [
    "# whether to log each feature and sequence status\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T17:39:02.833649Z",
     "start_time": "2020-03-24T17:39:02.829799Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T17:39:03.006390Z",
     "start_time": "2020-03-24T17:39:03.003614Z"
    }
   },
   "outputs": [],
   "source": [
    "# setup paths\n",
    "pwd = os.getcwd().replace(\"notebooks\",\"\")\n",
    "path_cache = pwd + 'cache/'\n",
    "path_data = pwd + 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T17:39:03.196010Z",
     "start_time": "2020-03-24T17:39:03.190661Z"
    }
   },
   "outputs": [],
   "source": [
    "# setup logging\n",
    "# any explicit log messages or uncaught errors to stdout and file /logs.log\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(threadName)-12.12s] [%(levelname)-5.5s]  %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"{0}/{1}.log\".format(pwd, \"logs\")),\n",
    "        logging.StreamHandler()\n",
    "    ])\n",
    "# init logger\n",
    "logger = logging.getLogger()\n",
    "# make logger aware of any uncaught exceptions\n",
    "def handle_exception(exc_type, exc_value, exc_traceback):\n",
    "    if issubclass(exc_type, KeyboardInterrupt):\n",
    "        sys.__excepthook__(exc_type, exc_value, exc_traceback)\n",
    "        return\n",
    "\n",
    "    logger.error(\"Uncaught exception\", exc_info=(exc_type, exc_value, exc_traceback))\n",
    "sys.excepthook = handle_exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T17:39:03.360138Z",
     "start_time": "2020-03-24T17:39:03.357159Z"
    }
   },
   "outputs": [],
   "source": [
    "from deepvideoclassification.architectures import Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model Params from Experiments Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T17:39:08.184957Z",
     "start_time": "2020-03-24T17:39:08.181040Z"
    }
   },
   "outputs": [],
   "source": [
    "experiment1 = {\n",
    "             'architecture': 'video_lrcnn_frozen',\n",
    "             'dropout': 0.2,\n",
    "             'layer_1_size': 128,\n",
    "             'layer_2_size': 128,\n",
    "             'layer_3_size': 256,\n",
    "             'model_id': 1,\n",
    "             'pooling': 'max',\n",
    "             'pretrained_model_name': 'resnet50',\n",
    "             'sequence_length': 5,\n",
    "             'sequence_model': \"LSTM\",\n",
    "             'sequence_model_layers': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T17:39:09.008882Z",
     "start_time": "2020-03-24T17:39:09.005401Z"
    }
   },
   "outputs": [],
   "source": [
    "experiment2 = {\n",
    "             'architecture': 'video_lrcnn_frozen',\n",
    "             'dropout': 0.2,\n",
    "             'layer_1_size': 512,\n",
    "             'layer_2_size': 512,\n",
    "             'layer_3_size': 256,\n",
    "             'model_id': 2,\n",
    "             'pooling': 'max',\n",
    "             'pretrained_model_name': 'resnet50',\n",
    "             'sequence_length': 5,\n",
    "             'sequence_model': \"LSTM\",\n",
    "             'sequence_model_layers': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T17:39:09.014637Z",
     "start_time": "2020-03-24T17:39:09.010969Z"
    }
   },
   "outputs": [],
   "source": [
    "experiment3 = {\n",
    "             'architecture': 'video_lrcnn_frozen',\n",
    "             'dropout': 0.2,\n",
    "             'layer_1_size': 512,\n",
    "             'layer_2_size': 512,\n",
    "             'layer_3_size': 128,\n",
    "             'model_id': 3,\n",
    "             'pooling': 'max',\n",
    "             'pretrained_model_name': 'resnet50',\n",
    "             'sequence_length': 3,\n",
    "             'sequence_model': \"LSTM\",\n",
    "             'sequence_model_layers': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T17:39:09.247611Z",
     "start_time": "2020-03-24T17:39:09.244255Z"
    }
   },
   "outputs": [],
   "source": [
    "experiment4 = {\n",
    "             'architecture': 'video_lrcnn_frozen',\n",
    "             'dropout': 0.2,\n",
    "             'layer_1_size': 512,\n",
    "             'layer_2_size': 512,\n",
    "             'layer_3_size': 512,\n",
    "             'model_id': 4,\n",
    "             'pooling': 'max',\n",
    "             'pretrained_model_name': 'resnet50',\n",
    "             'sequence_length': 5,\n",
    "             'sequence_model': \"GRU\",\n",
    "             'sequence_model_layers': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T17:39:09.253843Z",
     "start_time": "2020-03-24T17:39:09.249540Z"
    }
   },
   "outputs": [],
   "source": [
    "experiment5 = {\n",
    "             'architecture': 'video_lrcnn_frozen',\n",
    "             'dropout': 0.2,\n",
    "             'layer_1_size': 256,\n",
    "             'layer_2_size': 128,\n",
    "             'layer_3_size': 0,\n",
    "             'model_id': 5,\n",
    "             'pooling': 'max',\n",
    "             'pretrained_model_name': 'resnet50',\n",
    "             'sequence_length': 5,\n",
    "             'sequence_model': \"LSTM\",\n",
    "             'sequence_model_layers': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T17:39:09.259124Z",
     "start_time": "2020-03-24T17:39:09.256086Z"
    }
   },
   "outputs": [],
   "source": [
    "experiment6 = {\n",
    "             'architecture': 'image_mlp_frozen',\n",
    "             'dropout': 0.2,\n",
    "             'layer_1_size': 128,\n",
    "             'layer_2_size': 512,\n",
    "             'layer_3_size': 128,\n",
    "             'model_id': 6,\n",
    "             'pooling': 'max',\n",
    "             'pretrained_model_name': 'resnet50',\n",
    "             'sequence_length': 1,\n",
    "             'sequence_model': \"\",\n",
    "             'sequence_model_layers': \"\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T17:39:09.264003Z",
     "start_time": "2020-03-24T17:39:09.260971Z"
    }
   },
   "outputs": [],
   "source": [
    "experiment7 = {\n",
    "             'architecture': 'video_mlp_concat',\n",
    "             'dropout': 0.2,\n",
    "             'layer_1_size': 128,\n",
    "             'layer_2_size': 128,\n",
    "             'layer_3_size': 512,\n",
    "             'model_id': 7,\n",
    "             'pooling': 'max',\n",
    "             'pretrained_model_name': 'resnet50',\n",
    "             'sequence_length': 3,\n",
    "             'sequence_model': \"\",\n",
    "             'sequence_model_layers': \"\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T17:39:09.271292Z",
     "start_time": "2020-03-24T17:39:09.265809Z"
    }
   },
   "outputs": [],
   "source": [
    "experiments = [experiment1, experiment2, experiment3, experiment4, experiment5, experiment6, experiment7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T18:19:29.784477Z",
     "start_time": "2020-03-24T17:39:09.859448Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-24 17:39:09,862 [MainThread  ] [INFO ]  Begin experiment for model_id=1 on GPU:1 \n",
      "2020-03-24 17:39:09,864 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1   XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "{'layer_3_size': 256, 'pretrained_model_name': 'resnet50', 'dropout': 0.2, 'architecture': 'video_lrcnn_frozen', 'sequence_length': 5, 'layer_2_size': 128, 'sequence_model': 'LSTM', 'sequence_model_layers': 2, 'pooling': 'max', 'model_id': 1, 'layer_1_size': 128}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-24 17:39:10,134 [MainThread  ] [INFO ]  resizing vid 1/46 to 224x224\n",
      "2020-03-24 17:39:11,745 [MainThread  ] [INFO ]  resizing vid 2/46 to 224x224\n",
      "2020-03-24 17:39:14,023 [MainThread  ] [INFO ]  resizing vid 3/46 to 224x224\n",
      "2020-03-24 17:39:15,622 [MainThread  ] [INFO ]  resizing vid 4/46 to 224x224\n",
      "2020-03-24 17:39:17,129 [MainThread  ] [INFO ]  resizing vid 5/46 to 224x224\n",
      "2020-03-24 17:39:20,526 [MainThread  ] [INFO ]  resizing vid 6/46 to 224x224\n",
      "2020-03-24 17:39:21,744 [MainThread  ] [INFO ]  resizing vid 7/46 to 224x224\n",
      "2020-03-24 17:39:24,862 [MainThread  ] [INFO ]  resizing vid 8/46 to 224x224\n",
      "2020-03-24 17:39:26,569 [MainThread  ] [INFO ]  resizing vid 9/46 to 224x224\n",
      "2020-03-24 17:39:29,291 [MainThread  ] [INFO ]  resizing vid 10/46 to 224x224\n",
      "2020-03-24 17:39:33,068 [MainThread  ] [INFO ]  resizing vid 11/46 to 224x224\n",
      "2020-03-24 17:39:36,657 [MainThread  ] [INFO ]  resizing vid 12/46 to 224x224\n",
      "2020-03-24 17:39:38,633 [MainThread  ] [INFO ]  resizing vid 13/46 to 224x224\n",
      "2020-03-24 17:39:40,138 [MainThread  ] [INFO ]  resizing vid 14/46 to 224x224\n",
      "2020-03-24 17:39:43,350 [MainThread  ] [INFO ]  resizing vid 15/46 to 224x224\n",
      "2020-03-24 17:39:44,855 [MainThread  ] [INFO ]  resizing vid 16/46 to 224x224\n",
      "2020-03-24 17:39:46,186 [MainThread  ] [INFO ]  resizing vid 17/46 to 224x224\n",
      "2020-03-24 17:39:48,638 [MainThread  ] [INFO ]  resizing vid 18/46 to 224x224\n",
      "2020-03-24 17:39:52,769 [MainThread  ] [INFO ]  resizing vid 19/46 to 224x224\n",
      "2020-03-24 17:39:59,427 [MainThread  ] [INFO ]  resizing vid 20/46 to 224x224\n",
      "2020-03-24 17:40:01,118 [MainThread  ] [INFO ]  resizing vid 21/46 to 224x224\n",
      "2020-03-24 17:40:03,084 [MainThread  ] [INFO ]  resizing vid 22/46 to 224x224\n",
      "2020-03-24 17:40:05,998 [MainThread  ] [INFO ]  resizing vid 23/46 to 224x224\n",
      "2020-03-24 17:40:07,895 [MainThread  ] [INFO ]  resizing vid 24/46 to 224x224\n",
      "2020-03-24 17:40:09,974 [MainThread  ] [INFO ]  resizing vid 25/46 to 224x224\n",
      "2020-03-24 17:40:13,100 [MainThread  ] [INFO ]  resizing vid 26/46 to 224x224\n",
      "2020-03-24 17:40:14,424 [MainThread  ] [INFO ]  resizing vid 27/46 to 224x224\n",
      "2020-03-24 17:40:15,995 [MainThread  ] [INFO ]  resizing vid 28/46 to 224x224\n",
      "2020-03-24 17:40:17,504 [MainThread  ] [INFO ]  resizing vid 29/46 to 224x224\n",
      "2020-03-24 17:40:21,367 [MainThread  ] [INFO ]  resizing vid 30/46 to 224x224\n",
      "2020-03-24 17:40:24,370 [MainThread  ] [INFO ]  resizing vid 31/46 to 224x224\n",
      "2020-03-24 17:40:30,417 [MainThread  ] [INFO ]  resizing vid 32/46 to 224x224\n",
      "2020-03-24 17:40:32,664 [MainThread  ] [INFO ]  resizing vid 33/46 to 224x224\n",
      "2020-03-24 17:40:34,256 [MainThread  ] [INFO ]  resizing vid 34/46 to 224x224\n",
      "2020-03-24 17:40:36,977 [MainThread  ] [INFO ]  resizing vid 35/46 to 224x224\n",
      "2020-03-24 17:40:39,331 [MainThread  ] [INFO ]  resizing vid 36/46 to 224x224\n",
      "2020-03-24 17:40:40,744 [MainThread  ] [INFO ]  resizing vid 37/46 to 224x224\n",
      "2020-03-24 17:40:43,871 [MainThread  ] [INFO ]  resizing vid 38/46 to 224x224\n",
      "2020-03-24 17:40:47,923 [MainThread  ] [INFO ]  resizing vid 39/46 to 224x224\n",
      "2020-03-24 17:40:54,411 [MainThread  ] [INFO ]  resizing vid 40/46 to 224x224\n",
      "2020-03-24 17:40:56,288 [MainThread  ] [INFO ]  resizing vid 41/46 to 224x224\n",
      "2020-03-24 17:41:10,655 [MainThread  ] [INFO ]  resizing vid 42/46 to 224x224\n",
      "2020-03-24 17:41:11,967 [MainThread  ] [INFO ]  resizing vid 43/46 to 224x224\n",
      "2020-03-24 17:41:13,741 [MainThread  ] [INFO ]  resizing vid 44/46 to 224x224\n",
      "2020-03-24 17:41:15,155 [MainThread  ] [INFO ]  resizing vid 45/46 to 224x224\n",
      "2020-03-24 17:41:16,467 [MainThread  ] [INFO ]  resizing vid 46/46 to 224x224\n",
      "2020-03-24 17:41:29,900 [MainThread  ] [INFO ]  Computing pretrained model features for video 1/46 using pretrained model: resnet50, pooling: max\n",
      "2020-03-24 17:41:36,500 [MainThread  ] [INFO ]  Computing pretrained model features for video 2/46 using pretrained model: resnet50, pooling: max\n",
      "2020-03-24 17:41:43,793 [MainThread  ] [INFO ]  Computing pretrained model features for video 3/46 using pretrained model: resnet50, pooling: max\n",
      "2020-03-24 17:41:48,930 [MainThread  ] [INFO ]  Computing pretrained model features for video 4/46 using pretrained model: resnet50, pooling: max\n",
      "2020-03-24 17:41:53,764 [MainThread  ] [INFO ]  Computing pretrained model features for video 5/46 using pretrained model: resnet50, pooling: max\n",
      "2020-03-24 17:42:04,624 [MainThread  ] [INFO ]  Computing pretrained model features for video 6/46 using pretrained model: resnet50, pooling: max\n",
      "2020-03-24 17:42:08,529 [MainThread  ] [INFO ]  Computing pretrained model features for video 7/46 using pretrained model: resnet50, pooling: max\n",
      "2020-03-24 17:42:18,471 [MainThread  ] [INFO ]  Computing pretrained model features for video 8/46 using pretrained model: resnet50, pooling: max\n",
      "2020-03-24 17:42:23,910 [MainThread  ] [INFO ]  Computing pretrained model features for video 9/46 using pretrained model: resnet50, pooling: max\n",
      "2020-03-24 17:42:32,632 [MainThread  ] [INFO ]  Computing pretrained model features for video 10/46 using pretrained model: resnet50, pooling: max\n",
      "2020-03-24 17:42:44,686 [MainThread  ] [INFO ]  Computing pretrained model features for video 11/46 using pretrained model: resnet50, pooling: max\n",
      "2020-03-24 17:42:56,152 [MainThread  ] [INFO ]  Computing pretrained model features for video 12/46 using pretrained model: resnet50, pooling: max\n",
      "2020-03-24 17:43:02,469 [MainThread  ] [INFO ]  Computing pretrained model features for video 13/46 using pretrained model: resnet50, pooling: max\n",
      "2020-03-24 17:43:07,279 [MainThread  ] [INFO ]  Computing pretrained model features for video 14/46 using pretrained model: resnet50, pooling: max\n",
      "2020-03-24 17:43:17,531 [MainThread  ] [INFO ]  Computing pretrained model features for video 15/46 using pretrained model: resnet50, pooling: max\n",
      "2020-03-24 17:43:22,358 [MainThread  ] [INFO ]  Computing pretrained model features for video 16/46 using pretrained model: resnet50, pooling: max\n",
      "2020-03-24 17:43:26,592 [MainThread  ] [INFO ]  Computing pretrained model features for video 17/46 using pretrained model: resnet50, pooling: max\n",
      "2020-03-24 17:43:34,425 [MainThread  ] [INFO ]  Computing pretrained model features for video 18/46 using pretrained model: resnet50, pooling: max\n",
      "2020-03-24 17:43:47,696 [MainThread  ] [INFO ]  Computing pretrained model features for video 19/46 using pretrained model: resnet50, pooling: max\n",
      "2020-03-24 17:44:08,775 [MainThread  ] [INFO ]  Computing pretrained model features for video 20/46 using pretrained model: resnet50, pooling: max\n",
      "2020-03-24 17:44:14,212 [MainThread  ] [INFO ]  Computing pretrained model features for video 21/46 using pretrained model: resnet50, pooling: max\n",
      "2020-03-24 17:44:20,519 [MainThread  ] [INFO ]  Computing pretrained model features for video 22/46 using pretrained model: resnet50, pooling: max\n",
      "2020-03-24 17:44:29,843 [MainThread  ] [INFO ]  Computing pretrained model features for video 23/46 using pretrained model: resnet50, pooling: max\n",
      "2020-03-24 17:44:35,850 [MainThread  ] [INFO ]  Computing pretrained model features for video 24/46 using pretrained model: resnet50, pooling: max\n",
      "2020-03-24 17:44:42,469 [MainThread  ] [INFO ]  Computing pretrained model features for video 25/46 using pretrained model: resnet50, pooling: max\n",
      "2020-03-24 17:44:52,380 [MainThread  ] [INFO ]  Computing pretrained model features for video 26/46 using pretrained model: resnet50, pooling: max\n",
      "2020-03-24 17:44:56,590 [MainThread  ] [INFO ]  Computing pretrained model features for video 27/46 using pretrained model: resnet50, pooling: max\n",
      "2020-03-24 17:45:01,673 [MainThread  ] [INFO ]  Computing pretrained model features for video 28/46 using pretrained model: resnet50, pooling: max\n",
      "2020-03-24 17:45:06,469 [MainThread  ] [INFO ]  Computing pretrained model features for video 29/46 using pretrained model: resnet50, pooling: max\n",
      "2020-03-24 17:45:18,799 [MainThread  ] [INFO ]  Computing pretrained model features for video 30/46 using pretrained model: resnet50, pooling: max\n",
      "2020-03-24 17:45:28,497 [MainThread  ] [INFO ]  Computing pretrained model features for video 31/46 using pretrained model: resnet50, pooling: max\n",
      "2020-03-24 17:45:47,733 [MainThread  ] [INFO ]  Computing pretrained model features for video 32/46 using pretrained model: resnet50, pooling: max\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-24 17:45:54,957 [MainThread  ] [INFO ]  Computing pretrained model features for video 33/46 using pretrained model: resnet50, pooling: max\n",
      "2020-03-24 17:46:00,057 [MainThread  ] [INFO ]  Computing pretrained model features for video 34/46 using pretrained model: resnet50, pooling: max\n",
      "2020-03-24 17:46:08,748 [MainThread  ] [INFO ]  Computing pretrained model features for video 35/46 using pretrained model: resnet50, pooling: max\n",
      "2020-03-24 17:46:16,260 [MainThread  ] [INFO ]  Computing pretrained model features for video 36/46 using pretrained model: resnet50, pooling: max\n",
      "2020-03-24 17:46:20,762 [MainThread  ] [INFO ]  Computing pretrained model features for video 37/46 using pretrained model: resnet50, pooling: max\n",
      "2020-03-24 17:46:30,660 [MainThread  ] [INFO ]  Computing pretrained model features for video 38/46 using pretrained model: resnet50, pooling: max\n",
      "2020-03-24 17:46:43,561 [MainThread  ] [INFO ]  Computing pretrained model features for video 39/46 using pretrained model: resnet50, pooling: max\n",
      "2020-03-24 17:47:04,257 [MainThread  ] [INFO ]  Computing pretrained model features for video 40/46 using pretrained model: resnet50, pooling: max\n",
      "2020-03-24 17:47:10,264 [MainThread  ] [INFO ]  Computing pretrained model features for video 41/46 using pretrained model: resnet50, pooling: max\n",
      "2020-03-24 17:47:56,173 [MainThread  ] [INFO ]  Computing pretrained model features for video 42/46 using pretrained model: resnet50, pooling: max\n",
      "2020-03-24 17:48:00,382 [MainThread  ] [INFO ]  Computing pretrained model features for video 43/46 using pretrained model: resnet50, pooling: max\n",
      "2020-03-24 17:48:06,065 [MainThread  ] [INFO ]  Computing pretrained model features for video 44/46 using pretrained model: resnet50, pooling: max\n",
      "2020-03-24 17:48:10,578 [MainThread  ] [INFO ]  Computing pretrained model features for video 45/46 using pretrained model: resnet50, pooling: max\n",
      "2020-03-24 17:48:14,793 [MainThread  ] [INFO ]  Computing pretrained model features for video 46/46 using pretrained model: resnet50, pooling: max\n",
      "2020-03-24 17:48:19,008 [MainThread  ] [INFO ]  Loading features sequence data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=10619, valid=1360, test=295\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.90809, saving model to /mnt/seals/models/1/model_round_1.h5\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.90809\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.90809 to 0.92353, saving model to /mnt/seals/models/1/model_round_1.h5\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.92353\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.92353 to 0.94926, saving model to /mnt/seals/models/1/model_round_1.h5\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.94926\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.94926 to 0.95147, saving model to /mnt/seals/models/1/model_round_1.h5\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.95147\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.95147\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.95147\n",
      "Epoch 00010: early stopping\n",
      "H1 {'loss': [0.4635749260846454, 0.39366549076092355, 0.33932876793192496, 0.2986179398877415, 0.2909860155760136, 0.26866403335186373, 0.26208892881544715, 0.24468734275263035, 0.23783805220407084, 0.23500235539134226], 'val_loss': [0.3435779746840982, 0.37832733638146343, 0.25394928543006673, 0.2519992863430696, 0.19821085018270157, 0.22803868072874406, 0.19737081895856295, 0.19587174355983733, 0.2104338749366648, 0.17814201633719837], 'val_acc': [0.9080882352941176, 0.8595588235294118, 0.9235294117647059, 0.9176470588235294, 0.9492647058823529, 0.9352941176470588, 0.9514705882352941, 0.9448529411764706, 0.9272058823529412, 0.9375], 'acc': [0.7877389584482137, 0.8285149260534496, 0.8614747150939606, 0.8831340051581938, 0.8880308880870182, 0.8976363123265888, 0.8982013371864364, 0.9089368113533837, 0.9113852529047977, 0.9143045484115988]}\n",
      "stopped_epoch1 7\n",
      "10\n",
      "0.9448529411764706\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.95000, saving model to /mnt/seals/models/1/model_round_2.h5\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.95000 to 0.95809, saving model to /mnt/seals/models/1/model_round_2.h5\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.95809\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.95809\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.95809\n",
      "Epoch 00005: early stopping\n",
      "H2 {'loss': [0.20360606741109286, 0.20283084599123533, 0.19618044171893828, 0.19419011618822396, 0.1927627547670302], 'val_loss': [0.16340240310220158, 0.14312425054171507, 0.15712806188008366, 0.15429128934355343, 0.15883971750736237], 'val_acc': [0.95, 0.9580882352941177, 0.9529411764705882, 0.9492647058823529, 0.9514705882352941], 'acc': [0.9270176099612782, 0.9291835389564755, 0.9289010264620021, 0.9319144928901026, 0.930878613782991]}\n",
      "stopped_epoch2 2\n",
      "5\n",
      "0.9529411764705882\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.95147, saving model to /mnt/seals/models/1/model_round_3.h5\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.95147 to 0.95221, saving model to /mnt/seals/models/1/model_round_3.h5\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.95221 to 0.95588, saving model to /mnt/seals/models/1/model_round_3.h5\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.95588\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.95588\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.95588\n",
      "Epoch 00006: early stopping\n",
      "H3 {'loss': [0.18927187610732285, 0.1866190313650217, 0.18686021523984636, 0.18951508583423277, 0.18776666232478495, 0.18273523305362538], 'val_loss': [0.15726070868618347, 0.14997435720527874, 0.14679306149482726, 0.14698231868884143, 0.14478740604484783, 0.14356159690548392], 'val_acc': [0.9514705882352941, 0.9522058823529411, 0.9558823529411765, 0.9536764705882353, 0.9536764705882353, 0.9522058823529411], 'acc': [0.9323853470924626, 0.9328562012050142, 0.9321028345025678, 0.9320086636766897, 0.9324795178060804, 0.9362463508973363]}\n",
      "stopped_epoch3 3\n",
      "6\n",
      "0.9536764705882353\n",
      "best fit round 3 0.9536764705882353\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 5, 128)            1114624   \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 5, 128)            131584    \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               164096    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 1,410,818\n",
      "Trainable params: 1,410,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "295/295 [==============================] - 2s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-24 17:52:42,036 [MainThread  ] [INFO ]  {\n",
      "    \"architecture\": \"video_lrcnn_frozen\",\n",
      "    \"batch_size\": 32,\n",
      "    \"class_names\": \"\",\n",
      "    \"convolution_kernel_size\": 3,\n",
      "    \"data_total_rows_test\": 295,\n",
      "    \"data_total_rows_train\": 10619,\n",
      "    \"data_total_rows_valid\": 1360,\n",
      "    \"dropout\": 0.2,\n",
      "    \"fit_best_round\": 3,\n",
      "    \"fit_dt_test_duration_seconds\": \"1\",\n",
      "    \"fit_dt_test_end\": \"2020-03-24 17:52:41\",\n",
      "    \"fit_dt_test_start\": \"2020-03-24 17:52:39\",\n",
      "    \"fit_dt_train_duration_seconds\": \"257\",\n",
      "    \"fit_dt_train_end\": \"2020-03-24 17:52:37\",\n",
      "    \"fit_dt_train_start\": \"2020-03-24 17:48:20\",\n",
      "    \"fit_num_epochs\": 15,\n",
      "    \"fit_stopped_epoch1\": 7,\n",
      "    \"fit_stopped_epoch2\": 2,\n",
      "    \"fit_stopped_epoch3\": 3,\n",
      "    \"fit_test_acc\": 0.888135593220339,\n",
      "    \"fit_train_acc\": 0.9320086636766897,\n",
      "    \"fit_train_loss\": 0.18951508583423277,\n",
      "    \"fit_val_acc\": 0.9536764705882353,\n",
      "    \"fit_val_loss\": 0.14698231868884143,\n",
      "    \"frame_size\": [\n",
      "        224,\n",
      "        224\n",
      "    ],\n",
      "    \"layer_1_size\": 128,\n",
      "    \"layer_2_size\": 128,\n",
      "    \"layer_3_size\": 256,\n",
      "    \"model_id\": 1,\n",
      "    \"model_param_count\": 1410818,\n",
      "    \"model_weights_path\": null,\n",
      "    \"num_features\": 2048,\n",
      "    \"path_model\": \"/mnt/seals/models/1/\",\n",
      "    \"pooling\": \"max\",\n",
      "    \"pretrained_model_name\": \"resnet50\",\n",
      "    \"sequence_length\": 5,\n",
      "    \"sequence_model\": \"LSTM\",\n",
      "    \"sequence_model_layers\": 2,\n",
      "    \"verbose\": true\n",
      "}\n",
      "2020-03-24 17:52:42,037 [MainThread  ] [INFO ]  model 1 test acc: 0.888135593220339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_weights_path': None, 'data_total_rows_train': 10619, 'fit_stopped_epoch1': 7, 'layer_1_size': 128, 'layer_3_size': 256, 'class_names': '', 'fit_stopped_epoch2': 2, 'layer_2_size': 128, 'fit_num_epochs': 15, 'pretrained_model_name': 'resnet50', 'sequence_model_layers': 2, 'frame_size': (224, 224), 'fit_stopped_epoch3': 3, 'architecture': 'video_lrcnn_frozen', 'data_total_rows_valid': 1360, 'sequence_model': 'LSTM', 'fit_dt_test_end': '2020-03-24 17:52:41', 'data_total_rows_test': 295, 'pooling': 'max', 'path_model': '/mnt/seals/models/1/', 'fit_dt_train_start': '2020-03-24 17:48:20', 'dropout': 0.2, 'fit_best_round': 3, 'fit_dt_test_duration_seconds': '1', 'convolution_kernel_size': 3, 'fit_dt_train_duration_seconds': '257', 'fit_test_acc': 0.888135593220339, 'fit_train_acc': 0.9320086636766897, 'model_param_count': 1410818, 'fit_dt_test_start': '2020-03-24 17:52:39', 'num_features': 2048, 'fit_val_acc': 0.9536764705882353, 'fit_train_loss': 0.18951508583423277, 'batch_size': 32, 'model_id': 1, 'sequence_length': 5, 'fit_dt_train_end': '2020-03-24 17:52:37', 'verbose': True, 'fit_val_loss': 0.14698231868884143}\n",
      "gsutil -m rsync -r /mnt/seals/models/1/ gs://thesis-penguins/models/1/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-24 17:52:43,903 [MainThread  ] [INFO ]  Begin experiment for model_id=2 on GPU:1 \n",
      "2020-03-24 17:52:43,908 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XX\n",
      "upload error\n",
      "2   XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "{'layer_3_size': 256, 'pretrained_model_name': 'resnet50', 'dropout': 0.2, 'architecture': 'video_lrcnn_frozen', 'sequence_length': 5, 'layer_2_size': 512, 'sequence_model': 'LSTM', 'sequence_model_layers': 2, 'pooling': 'max', 'model_id': 2, 'layer_1_size': 512}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-24 17:52:44,171 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/resnet50/max/\n",
      "2020-03-24 17:52:44,172 [MainThread  ] [INFO ]  Loading features sequence data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=10619, valid=1360, test=295\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.86838, saving model to /mnt/seals/models/2/model_round_1.h5\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.86838 to 0.89485, saving model to /mnt/seals/models/2/model_round_1.h5\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.89485 to 0.92426, saving model to /mnt/seals/models/2/model_round_1.h5\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.92426\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.92426 to 0.93382, saving model to /mnt/seals/models/2/model_round_1.h5\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.93382 to 0.95074, saving model to /mnt/seals/models/2/model_round_1.h5\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.95074\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.95074\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.95074\n",
      "Epoch 00009: early stopping\n",
      "H1 {'loss': [0.45979542739647955, 0.37386098666002054, 0.353062000864811, 0.3130546651120374, 0.27161563761558266, 0.2800391512911629, 0.26942101799562745, 0.25122517489064533, 0.23507864444210252], 'val_loss': [0.35180843612727, 0.30166522965711706, 0.2721900796189028, 0.25727156277965096, 0.19768343795748317, 0.17161929169121912, 0.2153246043359532, 0.1631452623535605, 0.19204535975175746], 'val_acc': [0.8683823529411765, 0.8948529411764706, 0.924264705882353, 0.899264705882353, 0.9338235294117647, 0.950735294117647, 0.9411764705882353, 0.9492647058823529, 0.9433823529411764], 'acc': [0.795178453692587, 0.8477257746280121, 0.8573311988675827, 0.8788963178814171, 0.9010264619627806, 0.8972596289276549, 0.8993313872092344, 0.907712590656259, 0.9176946982554723]}\n",
      "stopped_epoch1 6\n",
      "9\n",
      "0.9411764705882353\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.95956, saving model to /mnt/seals/models/2/model_round_2.h5\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.95956\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.95956\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.95956\n",
      "Epoch 00004: early stopping\n",
      "H2 {'loss': [0.1969837647256614, 0.18723643963698872, 0.1893778498494919, 0.18836109857149902], 'val_loss': [0.1257167588261997, 0.14737085463369595, 0.14646759747582325, 0.13632830206085653], 'val_acc': [0.9595588235294118, 0.9522058823529411, 0.9529411764705882, 0.9566176470588236], 'acc': [0.9304077597321826, 0.9337037385424962, 0.9334212261602831, 0.9338920802335436]}\n",
      "stopped_epoch2 1\n",
      "4\n",
      "0.9522058823529411\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.95735, saving model to /mnt/seals/models/2/model_round_3.h5\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.95735\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.95735\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.95735\n",
      "Epoch 00004: early stopping\n",
      "H3 {'loss': [0.17811805661794033, 0.1806517765424112, 0.1826839188219228, 0.1799692748975188], 'val_loss': [0.13475622788948172, 0.1401411994415171, 0.13499946839669172, 0.13500069327214184], 'val_acc': [0.9573529411764706, 0.9544117647058824, 0.9573529411764706, 0.9566176470588236], 'acc': [0.936623034256979, 0.9378472549765559, 0.9368113759087353, 0.9363405217625056]}\n",
      "stopped_epoch3 1\n",
      "4\n",
      "0.9544117647058824\n",
      "best fit round 3 0.9544117647058824\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 5, 512)            5244928   \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 5, 512)            2099200   \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 2560)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               655616    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 8,000,258\n",
      "Trainable params: 8,000,258\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "295/295 [==============================] - 2s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-24 17:58:16,845 [MainThread  ] [INFO ]  {\n",
      "    \"architecture\": \"video_lrcnn_frozen\",\n",
      "    \"batch_size\": 32,\n",
      "    \"class_names\": \"\",\n",
      "    \"convolution_kernel_size\": 3,\n",
      "    \"data_total_rows_test\": 295,\n",
      "    \"data_total_rows_train\": 10619,\n",
      "    \"data_total_rows_valid\": 1360,\n",
      "    \"dropout\": 0.2,\n",
      "    \"fit_best_round\": 3,\n",
      "    \"fit_dt_test_duration_seconds\": \"2\",\n",
      "    \"fit_dt_test_end\": \"2020-03-24 17:58:16\",\n",
      "    \"fit_dt_test_start\": \"2020-03-24 17:58:13\",\n",
      "    \"fit_dt_train_duration_seconds\": \"325\",\n",
      "    \"fit_dt_train_end\": \"2020-03-24 17:58:11\",\n",
      "    \"fit_dt_train_start\": \"2020-03-24 17:52:45\",\n",
      "    \"fit_num_epochs\": 11,\n",
      "    \"fit_stopped_epoch1\": 6,\n",
      "    \"fit_stopped_epoch2\": 1,\n",
      "    \"fit_stopped_epoch3\": 1,\n",
      "    \"fit_test_acc\": 0.888135593220339,\n",
      "    \"fit_train_acc\": 0.9378472549765559,\n",
      "    \"fit_train_loss\": 0.1806517765424112,\n",
      "    \"fit_val_acc\": 0.9544117647058824,\n",
      "    \"fit_val_loss\": 0.1401411994415171,\n",
      "    \"frame_size\": [\n",
      "        224,\n",
      "        224\n",
      "    ],\n",
      "    \"layer_1_size\": 512,\n",
      "    \"layer_2_size\": 512,\n",
      "    \"layer_3_size\": 256,\n",
      "    \"model_id\": 2,\n",
      "    \"model_param_count\": 8000258,\n",
      "    \"model_weights_path\": null,\n",
      "    \"num_features\": 2048,\n",
      "    \"path_model\": \"/mnt/seals/models/2/\",\n",
      "    \"pooling\": \"max\",\n",
      "    \"pretrained_model_name\": \"resnet50\",\n",
      "    \"sequence_length\": 5,\n",
      "    \"sequence_model\": \"LSTM\",\n",
      "    \"sequence_model_layers\": 2,\n",
      "    \"verbose\": true\n",
      "}\n",
      "2020-03-24 17:58:16,846 [MainThread  ] [INFO ]  model 2 test acc: 0.888135593220339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_weights_path': None, 'data_total_rows_train': 10619, 'fit_stopped_epoch1': 6, 'layer_1_size': 512, 'layer_3_size': 256, 'class_names': '', 'fit_stopped_epoch2': 1, 'layer_2_size': 512, 'fit_num_epochs': 11, 'pretrained_model_name': 'resnet50', 'sequence_model_layers': 2, 'frame_size': (224, 224), 'fit_stopped_epoch3': 1, 'architecture': 'video_lrcnn_frozen', 'data_total_rows_valid': 1360, 'sequence_model': 'LSTM', 'fit_dt_test_end': '2020-03-24 17:58:16', 'data_total_rows_test': 295, 'pooling': 'max', 'path_model': '/mnt/seals/models/2/', 'fit_dt_train_start': '2020-03-24 17:52:45', 'dropout': 0.2, 'fit_best_round': 3, 'fit_dt_test_duration_seconds': '2', 'convolution_kernel_size': 3, 'fit_dt_train_duration_seconds': '325', 'fit_test_acc': 0.888135593220339, 'fit_train_acc': 0.9378472549765559, 'model_param_count': 8000258, 'fit_dt_test_start': '2020-03-24 17:58:13', 'num_features': 2048, 'fit_val_acc': 0.9544117647058824, 'fit_train_loss': 0.1806517765424112, 'batch_size': 32, 'model_id': 2, 'sequence_length': 5, 'fit_dt_train_end': '2020-03-24 17:58:11', 'verbose': True, 'fit_val_loss': 0.1401411994415171}\n",
      "gsutil -m rsync -r /mnt/seals/models/2/ gs://thesis-penguins/models/2/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-24 17:58:18,868 [MainThread  ] [INFO ]  Begin experiment for model_id=3 on GPU:1 \n",
      "2020-03-24 17:58:18,873 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XX\n",
      "upload error\n",
      "3   XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "{'layer_3_size': 128, 'pretrained_model_name': 'resnet50', 'dropout': 0.2, 'architecture': 'video_lrcnn_frozen', 'sequence_length': 3, 'layer_2_size': 512, 'sequence_model': 'LSTM', 'sequence_model_layers': 2, 'pooling': 'max', 'model_id': 3, 'layer_1_size': 512}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-24 17:58:19,135 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/resnet50/max/\n",
      "2020-03-24 17:58:19,136 [MainThread  ] [INFO ]  Loading features sequence data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=10697, valid=1370, test=299\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.88686, saving model to /mnt/seals/models/3/model_round_1.h5\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.88686 to 0.91460, saving model to /mnt/seals/models/3/model_round_1.h5\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91460\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.91460 to 0.92190, saving model to /mnt/seals/models/3/model_round_1.h5\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.92190\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.92190 to 0.92555, saving model to /mnt/seals/models/3/model_round_1.h5\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.92555 to 0.94526, saving model to /mnt/seals/models/3/model_round_1.h5\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.94526\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.94526 to 0.95401, saving model to /mnt/seals/models/3/model_round_1.h5\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.95401\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.95401\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.95401\n",
      "Epoch 00012: early stopping\n",
      "H1 {'loss': [0.4756651775150686, 0.387714215438589, 0.3502688027853563, 0.3145379891509908, 0.3186565642310847, 0.29145055030833633, 0.28125097764997414, 0.26448382695843775, 0.2688903287408329, 0.2428700394006971, 0.24602815857376686, 0.25588772697566636], 'val_loss': [0.3422550440269665, 0.2629568047767138, 0.3739368134171423, 0.2646779553298533, 0.3214325903976051, 0.21047921676705353, 0.1693043579802896, 0.20384102679082078, 0.1574083481174316, 0.2323711348711139, 0.179276189012249, 0.19983012658836197], 'val_acc': [0.8868613133465286, 0.9145985396239009, 0.8372262769371924, 0.9218978096968936, 0.865693430221864, 0.92554744473339, 0.9452554739304703, 0.9277372257552878, 0.9540145980180615, 0.9211678832986929, 0.9357664228355798, 0.9372262774592769], 'acc': [0.7871365803607749, 0.837804992064991, 0.8602411891240165, 0.8766944003102934, 0.8791249883200528, 0.8890343086958221, 0.8961391044218006, 0.9052070674020753, 0.898569692442704, 0.911190053285968, 0.9118444423670188, 0.9041787417032813]}\n",
      "stopped_epoch1 9\n",
      "12\n",
      "0.9211678832986929\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.95693, saving model to /mnt/seals/models/3/model_round_2.h5\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.95693\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.95693 to 0.95766, saving model to /mnt/seals/models/3/model_round_2.h5\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.95766\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.95766\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.95766\n",
      "Epoch 00006: early stopping\n",
      "H2 {'loss': [0.20395494417098567, 0.20432036747826676, 0.2002926323361917, 0.19414053122785768, 0.1932289708140014, 0.19158088364528253], 'val_loss': [0.14137538658441418, 0.14264991759818835, 0.14907852841989838, 0.14664677860092942, 0.14824114139497716, 0.1409840824830271], 'val_acc': [0.9569343060472586, 0.9562043790399594, 0.9576642330545578, 0.9547445250253608, 0.9569343060472586, 0.9576642330545578], 'acc': [0.9308217257174909, 0.9310086940263625, 0.9292324950976539, 0.9337197345105734, 0.9337197345050015, 0.9321305038795924]}\n",
      "stopped_epoch2 3\n",
      "6\n",
      "0.9547445250253608\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.95912, saving model to /mnt/seals/models/3/model_round_3.h5\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.95912\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.95912\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.95912\n",
      "Epoch 00004: early stopping\n",
      "H3 {'loss': [0.1880828505149481, 0.18777861665473583, 0.18491009340655573, 0.18977039573771426], 'val_loss': [0.14009510609355286, 0.14031871805225846, 0.14049016783272264, 0.1419889002820871], 'val_acc': [0.9591240870691564, 0.9591240870691564, 0.9583941600618572, 0.9569343060472586], 'acc': [0.9322239880340283, 0.935589417604862, 0.937646068991306, 0.9348415443693755]}\n",
      "stopped_epoch3 1\n",
      "4\n",
      "0.9591240870691564\n",
      "best fit round 3 0.9591240870691564\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 3, 512)            5244928   \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 3, 512)            2099200   \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 128)               196736    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 7,541,122\n",
      "Trainable params: 7,541,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "299/299 [==============================] - 2s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-24 18:03:53,047 [MainThread  ] [INFO ]  {\n",
      "    \"architecture\": \"video_lrcnn_frozen\",\n",
      "    \"batch_size\": 32,\n",
      "    \"class_names\": \"\",\n",
      "    \"convolution_kernel_size\": 3,\n",
      "    \"data_total_rows_test\": 299,\n",
      "    \"data_total_rows_train\": 10697,\n",
      "    \"data_total_rows_valid\": 1370,\n",
      "    \"dropout\": 0.2,\n",
      "    \"fit_best_round\": 3,\n",
      "    \"fit_dt_test_duration_seconds\": \"2\",\n",
      "    \"fit_dt_test_end\": \"2020-03-24 18:03:52\",\n",
      "    \"fit_dt_test_start\": \"2020-03-24 18:03:49\",\n",
      "    \"fit_dt_train_duration_seconds\": \"326\",\n",
      "    \"fit_dt_train_end\": \"2020-03-24 18:03:46\",\n",
      "    \"fit_dt_train_start\": \"2020-03-24 17:58:20\",\n",
      "    \"fit_num_epochs\": 16,\n",
      "    \"fit_stopped_epoch1\": 9,\n",
      "    \"fit_stopped_epoch2\": 3,\n",
      "    \"fit_stopped_epoch3\": 1,\n",
      "    \"fit_test_acc\": 0.8929765886287625,\n",
      "    \"fit_train_acc\": 0.935589417604862,\n",
      "    \"fit_train_loss\": 0.18777861665473583,\n",
      "    \"fit_val_acc\": 0.9591240870691564,\n",
      "    \"fit_val_loss\": 0.14031871805225846,\n",
      "    \"frame_size\": [\n",
      "        224,\n",
      "        224\n",
      "    ],\n",
      "    \"layer_1_size\": 512,\n",
      "    \"layer_2_size\": 512,\n",
      "    \"layer_3_size\": 128,\n",
      "    \"model_id\": 3,\n",
      "    \"model_param_count\": 7541122,\n",
      "    \"model_weights_path\": null,\n",
      "    \"num_features\": 2048,\n",
      "    \"path_model\": \"/mnt/seals/models/3/\",\n",
      "    \"pooling\": \"max\",\n",
      "    \"pretrained_model_name\": \"resnet50\",\n",
      "    \"sequence_length\": 3,\n",
      "    \"sequence_model\": \"LSTM\",\n",
      "    \"sequence_model_layers\": 2,\n",
      "    \"verbose\": true\n",
      "}\n",
      "2020-03-24 18:03:53,048 [MainThread  ] [INFO ]  model 3 test acc: 0.8929765886287625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_weights_path': None, 'data_total_rows_train': 10697, 'fit_stopped_epoch1': 9, 'layer_1_size': 512, 'layer_3_size': 128, 'class_names': '', 'fit_stopped_epoch2': 3, 'layer_2_size': 512, 'fit_num_epochs': 16, 'pretrained_model_name': 'resnet50', 'sequence_model_layers': 2, 'frame_size': (224, 224), 'fit_stopped_epoch3': 1, 'architecture': 'video_lrcnn_frozen', 'data_total_rows_valid': 1370, 'sequence_model': 'LSTM', 'fit_dt_test_end': '2020-03-24 18:03:52', 'data_total_rows_test': 299, 'pooling': 'max', 'path_model': '/mnt/seals/models/3/', 'fit_dt_train_start': '2020-03-24 17:58:20', 'dropout': 0.2, 'fit_best_round': 3, 'fit_dt_test_duration_seconds': '2', 'convolution_kernel_size': 3, 'fit_dt_train_duration_seconds': '326', 'fit_test_acc': 0.8929765886287625, 'fit_train_acc': 0.935589417604862, 'model_param_count': 7541122, 'fit_dt_test_start': '2020-03-24 18:03:49', 'num_features': 2048, 'fit_val_acc': 0.9591240870691564, 'fit_train_loss': 0.18777861665473583, 'batch_size': 32, 'model_id': 3, 'sequence_length': 3, 'fit_dt_train_end': '2020-03-24 18:03:46', 'verbose': True, 'fit_val_loss': 0.14031871805225846}\n",
      "gsutil -m rsync -r /mnt/seals/models/3/ gs://thesis-penguins/models/3/\n",
      "XX\n",
      "upload error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-24 18:03:55,222 [MainThread  ] [INFO ]  Begin experiment for model_id=4 on GPU:1 \n",
      "2020-03-24 18:03:55,226 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4   XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "{'layer_3_size': 512, 'pretrained_model_name': 'resnet50', 'dropout': 0.2, 'architecture': 'video_lrcnn_frozen', 'sequence_length': 5, 'layer_2_size': 512, 'sequence_model': 'GRU', 'sequence_model_layers': 2, 'pooling': 'max', 'model_id': 4, 'layer_1_size': 512}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-24 18:03:55,494 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/resnet50/max/\n",
      "2020-03-24 18:03:55,495 [MainThread  ] [INFO ]  Loading features sequence data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=10619, valid=1360, test=295\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.86250, saving model to /mnt/seals/models/4/model_round_1.h5\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.86250 to 0.91103, saving model to /mnt/seals/models/4/model_round_1.h5\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.91103 to 0.93309, saving model to /mnt/seals/models/4/model_round_1.h5\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.93309\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.93309 to 0.94559, saving model to /mnt/seals/models/4/model_round_1.h5\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.94559\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.94559\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.94559\n",
      "Epoch 00008: early stopping\n",
      "H1 {'loss': [0.5029792139936902, 0.41889569575879315, 0.3940099674476182, 0.3414729016150938, 0.3357645770494003, 0.34205284077901826, 0.3316957903807531, 0.305420697836937], 'val_loss': [0.39037936960949615, 0.32840905575191276, 0.21040156185626985, 0.21835550473016851, 0.2166075794135823, 0.2169386425439049, 0.32303108029505784, 0.29322884117855746], 'val_acc': [0.8625, 0.9110294117647059, 0.9330882352941177, 0.9323529411764706, 0.9455882352941176, 0.9330882352941177, 0.8757352941176471, 0.8948529411764706], 'acc': [0.766833035086427, 0.8256898013725267, 0.843676429115252, 0.8667482813992667, 0.8712684810975478, 0.8675958187760399, 0.8760711931050728, 0.8875600338622062]}\n",
      "stopped_epoch1 5\n",
      "8\n",
      "0.9330882352941177\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.94338, saving model to /mnt/seals/models/4/model_round_2.h5\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.94338\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.94338\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.94338\n",
      "Epoch 00004: early stopping\n",
      "H2 {'loss': [0.26490214553068153, 0.25078405744500254, 0.24471718435492237, 0.2460685844575857], 'val_loss': [0.17410946207887987, 0.1812260745202794, 0.1745220612953691, 0.17919795925126356], 'val_acc': [0.9433823529411764, 0.9397058823529412, 0.9426470588235294, 0.9419117647058823], 'acc': [0.9060175157343222, 0.9139278652035076, 0.912326961124288, 0.9149637441927457]}\n",
      "stopped_epoch2 1\n",
      "4\n",
      "0.9397058823529412\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.93897, saving model to /mnt/seals/models/4/model_round_3.h5\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.93897\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.93897 to 0.94412, saving model to /mnt/seals/models/4/model_round_3.h5\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.94412\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.94412\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.94412\n",
      "Epoch 00006: early stopping\n",
      "H3 {'loss': [0.2406937144630058, 0.24161035201342745, 0.23810343051857055, 0.23652223213399934, 0.24012189799375436, 0.23656468302690664], 'val_loss': [0.17892997212269726, 0.17800993472337723, 0.17170264159931856, 0.1717782049494631, 0.17331110642236822, 0.17538584803833682], 'val_acc': [0.9389705882352941, 0.9382352941176471, 0.9441176470588235, 0.9441176470588235, 0.9419117647058823, 0.9397058823529412], 'acc': [0.9157171108951923, 0.9147754026139587, 0.9148695734229978, 0.9187305772278715, 0.9159054524908183, 0.917506356586877]}\n",
      "stopped_epoch3 3\n",
      "6\n",
      "0.9441176470588235\n",
      "best fit round 3 0.9441176470588235\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_1 (GRU)                  (None, 5, 512)            3933696   \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 5, 512)            1574400   \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 2560)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 512)               1311232   \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 6,820,354\n",
      "Trainable params: 6,820,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "295/295 [==============================] - 3s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-24 18:09:10,699 [MainThread  ] [INFO ]  {\n",
      "    \"architecture\": \"video_lrcnn_frozen\",\n",
      "    \"batch_size\": 32,\n",
      "    \"class_names\": \"\",\n",
      "    \"convolution_kernel_size\": 3,\n",
      "    \"data_total_rows_test\": 295,\n",
      "    \"data_total_rows_train\": 10619,\n",
      "    \"data_total_rows_valid\": 1360,\n",
      "    \"dropout\": 0.2,\n",
      "    \"fit_best_round\": 3,\n",
      "    \"fit_dt_test_duration_seconds\": \"2\",\n",
      "    \"fit_dt_test_end\": \"2020-03-24 18:09:09\",\n",
      "    \"fit_dt_test_start\": \"2020-03-24 18:09:07\",\n",
      "    \"fit_dt_train_duration_seconds\": \"306\",\n",
      "    \"fit_dt_train_end\": \"2020-03-24 18:09:03\",\n",
      "    \"fit_dt_train_start\": \"2020-03-24 18:03:56\",\n",
      "    \"fit_num_epochs\": 12,\n",
      "    \"fit_stopped_epoch1\": 5,\n",
      "    \"fit_stopped_epoch2\": 1,\n",
      "    \"fit_stopped_epoch3\": 3,\n",
      "    \"fit_test_acc\": 0.8745762711864407,\n",
      "    \"fit_train_acc\": 0.9187305772278715,\n",
      "    \"fit_train_loss\": 0.23652223213399934,\n",
      "    \"fit_val_acc\": 0.9441176470588235,\n",
      "    \"fit_val_loss\": 0.1717782049494631,\n",
      "    \"frame_size\": [\n",
      "        224,\n",
      "        224\n",
      "    ],\n",
      "    \"layer_1_size\": 512,\n",
      "    \"layer_2_size\": 512,\n",
      "    \"layer_3_size\": 512,\n",
      "    \"model_id\": 4,\n",
      "    \"model_param_count\": 6820354,\n",
      "    \"model_weights_path\": null,\n",
      "    \"num_features\": 2048,\n",
      "    \"path_model\": \"/mnt/seals/models/4/\",\n",
      "    \"pooling\": \"max\",\n",
      "    \"pretrained_model_name\": \"resnet50\",\n",
      "    \"sequence_length\": 5,\n",
      "    \"sequence_model\": \"GRU\",\n",
      "    \"sequence_model_layers\": 2,\n",
      "    \"verbose\": true\n",
      "}\n",
      "2020-03-24 18:09:10,700 [MainThread  ] [INFO ]  model 4 test acc: 0.8745762711864407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_weights_path': None, 'data_total_rows_train': 10619, 'fit_stopped_epoch1': 5, 'layer_1_size': 512, 'layer_3_size': 512, 'class_names': '', 'fit_stopped_epoch2': 1, 'layer_2_size': 512, 'fit_num_epochs': 12, 'pretrained_model_name': 'resnet50', 'sequence_model_layers': 2, 'frame_size': (224, 224), 'fit_stopped_epoch3': 3, 'architecture': 'video_lrcnn_frozen', 'data_total_rows_valid': 1360, 'sequence_model': 'GRU', 'fit_dt_test_end': '2020-03-24 18:09:09', 'data_total_rows_test': 295, 'pooling': 'max', 'path_model': '/mnt/seals/models/4/', 'fit_dt_train_start': '2020-03-24 18:03:56', 'dropout': 0.2, 'fit_best_round': 3, 'fit_dt_test_duration_seconds': '2', 'convolution_kernel_size': 3, 'fit_dt_train_duration_seconds': '306', 'fit_test_acc': 0.8745762711864407, 'fit_train_acc': 0.9187305772278715, 'model_param_count': 6820354, 'fit_dt_test_start': '2020-03-24 18:09:07', 'num_features': 2048, 'fit_val_acc': 0.9441176470588235, 'fit_train_loss': 0.23652223213399934, 'batch_size': 32, 'model_id': 4, 'sequence_length': 5, 'fit_dt_train_end': '2020-03-24 18:09:03', 'verbose': True, 'fit_val_loss': 0.1717782049494631}\n",
      "gsutil -m rsync -r /mnt/seals/models/4/ gs://thesis-penguins/models/4/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-24 18:09:13,088 [MainThread  ] [INFO ]  Begin experiment for model_id=5 on GPU:1 \n",
      "2020-03-24 18:09:13,093 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XX\n",
      "upload error\n",
      "5   XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "{'layer_3_size': 0, 'pretrained_model_name': 'resnet50', 'dropout': 0.2, 'architecture': 'video_lrcnn_frozen', 'sequence_length': 5, 'layer_2_size': 128, 'sequence_model': 'LSTM', 'sequence_model_layers': 2, 'pooling': 'max', 'model_id': 5, 'layer_1_size': 256}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-24 18:09:13,368 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/resnet50/max/\n",
      "2020-03-24 18:09:13,369 [MainThread  ] [INFO ]  Loading features sequence data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=10619, valid=1360, test=295\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.76618, saving model to /mnt/seals/models/5/model_round_1.h5\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.76618 to 0.91838, saving model to /mnt/seals/models/5/model_round_1.h5\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91838\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.91838 to 0.94926, saving model to /mnt/seals/models/5/model_round_1.h5\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.94926\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.94926 to 0.95074, saving model to /mnt/seals/models/5/model_round_1.h5\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.95074\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.95074\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.95074\n",
      "Epoch 00009: early stopping\n",
      "H1 {'loss': [0.4510660644742389, 0.36301522366811306, 0.31116408853670535, 0.28768510689494275, 0.2800399773015804, 0.2544869524558752, 0.2531016530352064, 0.2293103037931587, 0.22096665070963756], 'val_loss': [0.45359539915533625, 0.235001462522675, 0.2523641982499291, 0.1709246302352232, 0.1976096527541385, 0.15895898009047787, 0.22776075794416314, 0.18772483450524946, 0.30220402461640977], 'val_acc': [0.7661764705882353, 0.9183823529411764, 0.9088235294117647, 0.9492647058823529, 0.9404411764705882, 0.950735294117647, 0.9448529411764706, 0.9389705882352941, 0.8691176470588236], 'acc': [0.7974385534912104, 0.8488558244431285, 0.8774837554932449, 0.8921744044424955, 0.8943403333815627, 0.9065825407850123, 0.9069592240099427, 0.9172238440138212, 0.9153404275523885]}\n",
      "stopped_epoch1 6\n",
      "9\n",
      "0.9448529411764706\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.96029, saving model to /mnt/seals/models/5/model_round_2.h5\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.96029 to 0.96324, saving model to /mnt/seals/models/5/model_round_2.h5\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.96324\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.96324\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.96324\n",
      "Epoch 00005: early stopping\n",
      "H2 {'loss': [0.1907775199705738, 0.19060824254787465, 0.1879593690990425, 0.18459064303553085, 0.1817359114161363], 'val_loss': [0.14046070864971946, 0.13467281285454244, 0.1346089598887107, 0.14505244475953719, 0.14430800956838272], 'val_acc': [0.9602941176470589, 0.9632352941176471, 0.9580882352941177, 0.9529411764705882, 0.9485294117647058], 'acc': [0.93153780958659, 0.9348337885091641, 0.9343629343236433, 0.9361521800546191, 0.9372822299258656]}\n",
      "stopped_epoch2 2\n",
      "5\n",
      "0.9580882352941177\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.95588, saving model to /mnt/seals/models/5/model_round_3.h5\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.95588 to 0.95735, saving model to /mnt/seals/models/5/model_round_3.h5\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.95735 to 0.95882, saving model to /mnt/seals/models/5/model_round_3.h5\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.95882 to 0.96103, saving model to /mnt/seals/models/5/model_round_3.h5\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.96103\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.96103 to 0.96250, saving model to /mnt/seals/models/5/model_round_3.h5\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.96250\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.96250 to 0.96324, saving model to /mnt/seals/models/5/model_round_3.h5\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.96324\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.96324\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.96324\n",
      "Epoch 00011: early stopping\n",
      "H3 {'loss': [0.18143940210266632, 0.18012087945463698, 0.17837609035650634, 0.17209777157402542, 0.17272219753094745, 0.1723601211661201, 0.1719586892208369, 0.17938225379360856, 0.17702285208145502, 0.17456590925269752, 0.17352821339388017], 'val_loss': [0.13755252931047887, 0.1363033494528602, 0.1344435503377634, 0.1316568648990463, 0.13256684418986825, 0.13108551993089565, 0.13155005990582355, 0.12944755825926277, 0.13139068843687282, 0.13075832895496312, 0.13231481287409277], 'val_acc': [0.9558823529411765, 0.9573529411764706, 0.9588235294117647, 0.9610294117647059, 0.9602941176470589, 0.9625, 0.961764705882353, 0.9632352941176471, 0.9625, 0.961764705882353, 0.9610294117647059], 'acc': [0.9367172050660181, 0.9379414257463038, 0.9377530841113866, 0.9404840381011439, 0.9409548921912434, 0.9386947924094591, 0.9405782088316007, 0.937941425802434, 0.9367172050660181, 0.9395423298030713, 0.9390714757129717]}\n",
      "stopped_epoch3 8\n",
      "11\n",
      "0.9625\n",
      "best fit round 3 0.9625\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_9 (LSTM)                (None, 5, 256)            2360320   \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 128)               197120    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 2,557,698\n",
      "Trainable params: 2,557,698\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "295/295 [==============================] - 3s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-24 18:15:09,815 [MainThread  ] [INFO ]  {\n",
      "    \"architecture\": \"video_lrcnn_frozen\",\n",
      "    \"batch_size\": 32,\n",
      "    \"class_names\": \"\",\n",
      "    \"convolution_kernel_size\": 3,\n",
      "    \"data_total_rows_test\": 295,\n",
      "    \"data_total_rows_train\": 10619,\n",
      "    \"data_total_rows_valid\": 1360,\n",
      "    \"dropout\": 0.2,\n",
      "    \"fit_best_round\": 3,\n",
      "    \"fit_dt_test_duration_seconds\": \"3\",\n",
      "    \"fit_dt_test_end\": \"2020-03-24 18:15:08\",\n",
      "    \"fit_dt_test_start\": \"2020-03-24 18:15:05\",\n",
      "    \"fit_dt_train_duration_seconds\": \"347\",\n",
      "    \"fit_dt_train_end\": \"2020-03-24 18:15:01\",\n",
      "    \"fit_dt_train_start\": \"2020-03-24 18:09:14\",\n",
      "    \"fit_num_epochs\": 19,\n",
      "    \"fit_stopped_epoch1\": 6,\n",
      "    \"fit_stopped_epoch2\": 2,\n",
      "    \"fit_stopped_epoch3\": 8,\n",
      "    \"fit_test_acc\": 0.8983050847457628,\n",
      "    \"fit_train_acc\": 0.9367172050660181,\n",
      "    \"fit_train_loss\": 0.17702285208145502,\n",
      "    \"fit_val_acc\": 0.9625,\n",
      "    \"fit_val_loss\": 0.13139068843687282,\n",
      "    \"frame_size\": [\n",
      "        224,\n",
      "        224\n",
      "    ],\n",
      "    \"layer_1_size\": 256,\n",
      "    \"layer_2_size\": 128,\n",
      "    \"layer_3_size\": 0,\n",
      "    \"model_id\": 5,\n",
      "    \"model_param_count\": 2557698,\n",
      "    \"model_weights_path\": null,\n",
      "    \"num_features\": 2048,\n",
      "    \"path_model\": \"/mnt/seals/models/5/\",\n",
      "    \"pooling\": \"max\",\n",
      "    \"pretrained_model_name\": \"resnet50\",\n",
      "    \"sequence_length\": 5,\n",
      "    \"sequence_model\": \"LSTM\",\n",
      "    \"sequence_model_layers\": 2,\n",
      "    \"verbose\": true\n",
      "}\n",
      "2020-03-24 18:15:09,816 [MainThread  ] [INFO ]  model 5 test acc: 0.8983050847457628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_weights_path': None, 'data_total_rows_train': 10619, 'fit_stopped_epoch1': 6, 'layer_1_size': 256, 'layer_3_size': 0, 'class_names': '', 'fit_stopped_epoch2': 2, 'layer_2_size': 128, 'fit_num_epochs': 19, 'pretrained_model_name': 'resnet50', 'sequence_model_layers': 2, 'frame_size': (224, 224), 'fit_stopped_epoch3': 8, 'architecture': 'video_lrcnn_frozen', 'data_total_rows_valid': 1360, 'sequence_model': 'LSTM', 'fit_dt_test_end': '2020-03-24 18:15:08', 'data_total_rows_test': 295, 'pooling': 'max', 'path_model': '/mnt/seals/models/5/', 'fit_dt_train_start': '2020-03-24 18:09:14', 'dropout': 0.2, 'fit_best_round': 3, 'fit_dt_test_duration_seconds': '3', 'convolution_kernel_size': 3, 'fit_dt_train_duration_seconds': '347', 'fit_test_acc': 0.8983050847457628, 'fit_train_acc': 0.9367172050660181, 'model_param_count': 2557698, 'fit_dt_test_start': '2020-03-24 18:15:05', 'num_features': 2048, 'fit_val_acc': 0.9625, 'fit_train_loss': 0.17702285208145502, 'batch_size': 32, 'model_id': 5, 'sequence_length': 5, 'fit_dt_train_end': '2020-03-24 18:15:01', 'verbose': True, 'fit_val_loss': 0.13139068843687282}\n",
      "gsutil -m rsync -r /mnt/seals/models/5/ gs://thesis-penguins/models/5/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-24 18:15:12,372 [MainThread  ] [INFO ]  Begin experiment for model_id=6 on GPU:1 \n",
      "2020-03-24 18:15:12,374 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XX\n",
      "upload error\n",
      "6   XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "{'layer_3_size': 128, 'pretrained_model_name': 'resnet50', 'dropout': 0.2, 'architecture': 'image_mlp_frozen', 'sequence_length': 1, 'layer_2_size': 512, 'sequence_model': '', 'sequence_model_layers': '', 'pooling': 'max', 'model_id': 6, 'layer_1_size': 128}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-24 18:15:12,647 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/resnet50/max/\n",
      "2020-03-24 18:15:12,648 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=10775, valid=1380, test=303\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.86594, saving model to /mnt/seals/models/6/model_round_1.h5\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.86594 to 0.87391, saving model to /mnt/seals/models/6/model_round_1.h5\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.87391\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.87391\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.87391 to 0.89928, saving model to /mnt/seals/models/6/model_round_1.h5\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.89928\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.89928 to 0.92536, saving model to /mnt/seals/models/6/model_round_1.h5\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92536\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.92536 to 0.93478, saving model to /mnt/seals/models/6/model_round_1.h5\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.93478\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.93478\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.93478\n",
      "Epoch 00012: early stopping\n",
      "H1 {'loss': [0.5378303826823312, 0.380730203489693, 0.41984016323034284, 0.45586241001319444, 0.3926200411740146, 0.3544686399396777, 0.32331477139499515, 0.3242676531335041, 0.2773848241664417, 0.267297661705526, 0.24515515290667453, 0.2653656703482648], 'val_loss': [0.35415582181750865, 0.3354546299447184, 0.514847661619601, 0.37859028897423674, 0.3028028008298598, 0.36142574650221976, 0.22474266610283783, 0.25067196272421577, 0.21261022257200185, 0.36558800642041195, 0.2803604686929696, 0.3106040805578232], 'val_acc': [0.8659420289855072, 0.8739130434782608, 0.6789855072463769, 0.8615942028985507, 0.8992753623188405, 0.886231884057971, 0.9253623188405797, 0.922463768115942, 0.9347826086956522, 0.7992753623188406, 0.8840579710144928, 0.8623188405797102], 'acc': [0.7859860788254616, 0.8329466356921362, 0.8160556844602881, 0.8075174013533891, 0.8443619488950672, 0.8594895591702649, 0.8770301624351201, 0.8777726218097448, 0.8991183295106113, 0.9054292343000249, 0.9161948955750521, 0.9045011601149344]}\n",
      "stopped_epoch1 9\n",
      "12\n",
      "0.7992753623188406\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.93188, saving model to /mnt/seals/models/6/model_round_2.h5\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.93188\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.93188\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.93188\n",
      "Epoch 00004: early stopping\n",
      "H2 {'loss': [0.20568108663481516, 0.19435781214464015, 0.19634627914207442, 0.1950690196976584], 'val_loss': [0.19624731420822766, 0.19719060660488363, 0.19871789892946465, 0.22195278172907623], 'val_acc': [0.9318840579710145, 0.9318840579710145, 0.9311594202898551, 0.9210144927536232], 'acc': [0.9322505800906578, 0.9383758701138596, 0.9384686775384535, 0.9374477958679199]}\n",
      "stopped_epoch2 1\n",
      "4\n",
      "0.9318840579710145\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.93478, saving model to /mnt/seals/models/6/model_round_3.h5\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.93478 to 0.93551, saving model to /mnt/seals/models/6/model_round_3.h5\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.93551 to 0.93696, saving model to /mnt/seals/models/6/model_round_3.h5\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.93696\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.93696\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.93696\n",
      "Epoch 00006: early stopping\n",
      "H3 {'loss': [0.1873050549660924, 0.1840917250092234, 0.1847596557262049, 0.18306133930063578, 0.17998290142990875, 0.18310632099581153], 'val_loss': [0.19328500654386438, 0.18903517023376795, 0.18977451149536215, 0.18904000846804053, 0.18734974327726642, 0.1895694280664126], 'val_acc': [0.9347826086956522, 0.9355072463768116, 0.9369565217391305, 0.936231884057971, 0.936231884057971, 0.9355072463768116], 'acc': [0.9418097448238364, 0.9425522041763341, 0.9443155452878735, 0.9433874710198068, 0.9438515081040544, 0.9440371229698375]}\n",
      "stopped_epoch3 3\n",
      "6\n",
      "0.936231884057971\n",
      "best fit round 3 0.936231884057971\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 394,242\n",
      "Trainable params: 394,242\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "303/303 [==============================] - 3s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-24 18:17:26,175 [MainThread  ] [INFO ]  {\n",
      "    \"architecture\": \"image_mlp_frozen\",\n",
      "    \"batch_size\": 32,\n",
      "    \"class_names\": \"\",\n",
      "    \"convolution_kernel_size\": 3,\n",
      "    \"data_total_rows_test\": 303,\n",
      "    \"data_total_rows_train\": 10775,\n",
      "    \"data_total_rows_valid\": 1380,\n",
      "    \"dropout\": 0.2,\n",
      "    \"fit_best_round\": 3,\n",
      "    \"fit_dt_test_duration_seconds\": \"3\",\n",
      "    \"fit_dt_test_end\": \"2020-03-24 18:17:25\",\n",
      "    \"fit_dt_test_start\": \"2020-03-24 18:17:22\",\n",
      "    \"fit_dt_train_duration_seconds\": \"125\",\n",
      "    \"fit_dt_train_end\": \"2020-03-24 18:17:18\",\n",
      "    \"fit_dt_train_start\": \"2020-03-24 18:15:12\",\n",
      "    \"fit_num_epochs\": 16,\n",
      "    \"fit_stopped_epoch1\": 9,\n",
      "    \"fit_stopped_epoch2\": 1,\n",
      "    \"fit_stopped_epoch3\": 3,\n",
      "    \"fit_test_acc\": 0.8877887788778878,\n",
      "    \"fit_train_acc\": 0.9433874710198068,\n",
      "    \"fit_train_loss\": 0.18306133930063578,\n",
      "    \"fit_val_acc\": 0.936231884057971,\n",
      "    \"fit_val_loss\": 0.18904000846804053,\n",
      "    \"frame_size\": [\n",
      "        224,\n",
      "        224\n",
      "    ],\n",
      "    \"layer_1_size\": 128,\n",
      "    \"layer_2_size\": 512,\n",
      "    \"layer_3_size\": 128,\n",
      "    \"model_id\": 6,\n",
      "    \"model_param_count\": 394242,\n",
      "    \"model_weights_path\": null,\n",
      "    \"num_features\": 2048,\n",
      "    \"path_model\": \"/mnt/seals/models/6/\",\n",
      "    \"pooling\": \"max\",\n",
      "    \"pretrained_model_name\": \"resnet50\",\n",
      "    \"sequence_length\": 1,\n",
      "    \"sequence_model\": \"\",\n",
      "    \"sequence_model_layers\": \"\",\n",
      "    \"verbose\": true\n",
      "}\n",
      "2020-03-24 18:17:26,176 [MainThread  ] [INFO ]  model 6 test acc: 0.8877887788778878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_weights_path': None, 'data_total_rows_train': 10775, 'fit_stopped_epoch1': 9, 'layer_1_size': 128, 'layer_3_size': 128, 'class_names': '', 'fit_stopped_epoch2': 1, 'layer_2_size': 512, 'fit_num_epochs': 16, 'pretrained_model_name': 'resnet50', 'sequence_model_layers': '', 'frame_size': (224, 224), 'fit_stopped_epoch3': 3, 'architecture': 'image_mlp_frozen', 'data_total_rows_valid': 1380, 'sequence_model': '', 'fit_dt_test_end': '2020-03-24 18:17:25', 'data_total_rows_test': 303, 'pooling': 'max', 'path_model': '/mnt/seals/models/6/', 'fit_dt_train_start': '2020-03-24 18:15:12', 'dropout': 0.2, 'fit_best_round': 3, 'fit_dt_test_duration_seconds': '3', 'convolution_kernel_size': 3, 'fit_dt_train_duration_seconds': '125', 'fit_test_acc': 0.8877887788778878, 'fit_train_acc': 0.9433874710198068, 'model_param_count': 394242, 'fit_dt_test_start': '2020-03-24 18:17:22', 'num_features': 2048, 'fit_val_acc': 0.936231884057971, 'fit_train_loss': 0.18306133930063578, 'batch_size': 32, 'model_id': 6, 'sequence_length': 1, 'fit_dt_train_end': '2020-03-24 18:17:18', 'verbose': True, 'fit_val_loss': 0.18904000846804053}\n",
      "gsutil -m rsync -r /mnt/seals/models/6/ gs://thesis-penguins/models/6/\n",
      "XX\n",
      "upload error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-24 18:17:28,746 [MainThread  ] [INFO ]  Begin experiment for model_id=7 on GPU:1 \n",
      "2020-03-24 18:17:28,749 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7   XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "{'layer_3_size': 512, 'pretrained_model_name': 'resnet50', 'dropout': 0.2, 'architecture': 'video_mlp_concat', 'sequence_length': 3, 'layer_2_size': 128, 'sequence_model': '', 'sequence_model_layers': '', 'pooling': 'max', 'model_id': 7, 'layer_1_size': 128}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-24 18:17:29,022 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/resnet50/max/\n",
      "2020-03-24 18:17:29,023 [MainThread  ] [INFO ]  Loading features sequence data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=10697, valid=1370, test=299\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.70365, saving model to /mnt/seals/models/7/model_round_1.h5\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.70365\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.70365\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.70365\n",
      "Epoch 00004: early stopping\n",
      "H1 {'loss': [5.707842438580043, 5.733541692853408, 5.733541707162535, 5.733541706583038], 'val_loss': [4.750567271239566, 4.750567271239566, 4.750567271239566, 4.750567271239566], 'val_acc': [0.7036496352975385, 0.7036496352975385, 0.7036496352975385, 0.7036496352975385], 'acc': [0.6409273628147895, 0.642329625139685, 0.642329625150829, 0.6423296251452569]}\n",
      "stopped_epoch1 1\n",
      "4\n",
      "0.7036496352975385\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.70365, saving model to /mnt/seals/models/7/model_round_2.h5\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.70365\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.70365\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.70365\n",
      "Epoch 00004: early stopping\n",
      "H2 {'loss': [5.73354170288317, 5.733541699250168, 5.733541682333303, 5.733541696753871], 'val_loss': [4.750567271239566, 4.750567271239566, 4.750567271239566, 4.750567271239566], 'val_acc': [0.7036496352975385, 0.7036496352975385, 0.7036496352975385, 0.7036496352975385], 'acc': [0.642329625150829, 0.6423296251341128, 0.6423296251452569, 0.6423296251341128]}\n",
      "stopped_epoch2 1\n",
      "4\n",
      "0.7036496352975385\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.70365, saving model to /mnt/seals/models/7/model_round_3.h5\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.70365\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.70365\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.70365\n",
      "Epoch 00004: early stopping\n",
      "H3 {'loss': [5.733541691828144, 5.733541704131318, 5.733541669316901, 5.733541703328937], 'val_loss': [4.750567271239566, 4.750567271239566, 4.750567271239566, 4.750567271239566], 'val_acc': [0.7036496352975385, 0.7036496352975385, 0.7036496352975385, 0.7036496352975385], 'acc': [0.642329625150829, 0.6423296251299337, 0.642329625139685, 0.6423296251368988]}\n",
      "stopped_epoch3 1\n",
      "4\n",
      "0.7036496352975385\n",
      "best fit round 1 0.7036496352975385\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_12 (Flatten)         (None, 6144)              0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 128)               786560    \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 870,146\n",
      "Trainable params: 870,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "299/299 [==============================] - 3s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-24 18:19:27,089 [MainThread  ] [INFO ]  {\n",
      "    \"architecture\": \"video_mlp_concat\",\n",
      "    \"batch_size\": 32,\n",
      "    \"class_names\": \"\",\n",
      "    \"convolution_kernel_size\": 3,\n",
      "    \"data_total_rows_test\": 299,\n",
      "    \"data_total_rows_train\": 10697,\n",
      "    \"data_total_rows_valid\": 1370,\n",
      "    \"dropout\": 0.2,\n",
      "    \"fit_best_round\": 1,\n",
      "    \"fit_dt_test_duration_seconds\": \"3\",\n",
      "    \"fit_dt_test_end\": \"2020-03-24 18:19:26\",\n",
      "    \"fit_dt_test_start\": \"2020-03-24 18:19:22\",\n",
      "    \"fit_dt_train_duration_seconds\": \"109\",\n",
      "    \"fit_dt_train_end\": \"2020-03-24 18:19:18\",\n",
      "    \"fit_dt_train_start\": \"2020-03-24 18:17:29\",\n",
      "    \"fit_num_epochs\": 6,\n",
      "    \"fit_stopped_epoch1\": 1,\n",
      "    \"fit_stopped_epoch2\": 1,\n",
      "    \"fit_stopped_epoch3\": 1,\n",
      "    \"fit_test_acc\": 0.35785953177257523,\n",
      "    \"fit_train_acc\": 0.642329625139685,\n",
      "    \"fit_train_loss\": 5.733541692853408,\n",
      "    \"fit_val_acc\": 0.7036496352975385,\n",
      "    \"fit_val_loss\": 4.750567271239566,\n",
      "    \"frame_size\": [\n",
      "        224,\n",
      "        224\n",
      "    ],\n",
      "    \"layer_1_size\": 128,\n",
      "    \"layer_2_size\": 128,\n",
      "    \"layer_3_size\": 512,\n",
      "    \"model_id\": 7,\n",
      "    \"model_param_count\": 870146,\n",
      "    \"model_weights_path\": null,\n",
      "    \"num_features\": 2048,\n",
      "    \"path_model\": \"/mnt/seals/models/7/\",\n",
      "    \"pooling\": \"max\",\n",
      "    \"pretrained_model_name\": \"resnet50\",\n",
      "    \"sequence_length\": 3,\n",
      "    \"sequence_model\": \"\",\n",
      "    \"sequence_model_layers\": \"\",\n",
      "    \"verbose\": true\n",
      "}\n",
      "2020-03-24 18:19:27,090 [MainThread  ] [INFO ]  model 7 test acc: 0.35785953177257523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_weights_path': None, 'data_total_rows_train': 10697, 'fit_stopped_epoch1': 1, 'layer_1_size': 128, 'layer_3_size': 512, 'class_names': '', 'fit_stopped_epoch2': 1, 'layer_2_size': 128, 'fit_num_epochs': 6, 'pretrained_model_name': 'resnet50', 'sequence_model_layers': '', 'frame_size': (224, 224), 'fit_stopped_epoch3': 1, 'architecture': 'video_mlp_concat', 'data_total_rows_valid': 1370, 'sequence_model': '', 'fit_dt_test_end': '2020-03-24 18:19:26', 'data_total_rows_test': 299, 'pooling': 'max', 'path_model': '/mnt/seals/models/7/', 'fit_dt_train_start': '2020-03-24 18:17:29', 'dropout': 0.2, 'fit_best_round': 1, 'fit_dt_test_duration_seconds': '3', 'convolution_kernel_size': 3, 'fit_dt_train_duration_seconds': '109', 'fit_test_acc': 0.35785953177257523, 'fit_train_acc': 0.642329625139685, 'model_param_count': 870146, 'fit_dt_test_start': '2020-03-24 18:19:22', 'num_features': 2048, 'fit_val_acc': 0.7036496352975385, 'fit_train_loss': 5.733541692853408, 'batch_size': 32, 'model_id': 7, 'sequence_length': 3, 'fit_dt_train_end': '2020-03-24 18:19:18', 'verbose': True, 'fit_val_loss': 4.750567271239566}\n",
      "gsutil -m rsync -r /mnt/seals/models/7/ gs://thesis-penguins/models/7/\n",
      "XX\n",
      "upload error\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for experiment in experiments:\n",
    "    print(str(experiment[\"model_id\"]) + \"   \" + \"X\"*60)\n",
    "    logging.info(\"Begin experiment for model_id={} on GPU:{} \".format(experiment['model_id'], os.environ[\"CUDA_VISIBLE_DEVICES\"]))\n",
    "    print(experiment)\n",
    "\n",
    "    architecture = Architecture(model_id = experiment['model_id'], \n",
    "                                architecture = experiment['architecture'], \n",
    "                                sequence_length = experiment['sequence_length'], \n",
    "                                pretrained_model_name = experiment['pretrained_model_name'],\n",
    "                                pooling = experiment['pooling'],\n",
    "                                sequence_model = experiment['sequence_model'],\n",
    "                                sequence_model_layers = experiment['sequence_model_layers'],\n",
    "                                layer_1_size = experiment['layer_1_size'],\n",
    "                                layer_2_size = experiment['layer_2_size'],\n",
    "                                layer_3_size = experiment['layer_3_size'],\n",
    "                                dropout = experiment['dropout'],\n",
    "                                verbose=True)\n",
    "\n",
    "    architecture.train_model()\n",
    "\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T18:19:29.791354Z",
     "start_time": "2020-03-24T18:19:29.786935Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 'label_noseal', '1': 'label_seal'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "architecture.data.label_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model and predict on full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T18:19:29.799125Z",
     "start_time": "2020-03-24T18:19:29.793645Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger, TensorBoard\n",
    "from keras.layers import Dense, Flatten, Dropout, ZeroPadding3D, Input\n",
    "from keras.layers.recurrent import SimpleRNN, GRU, LSTM\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling3D, Conv3D, MaxPooling2D, Convolution1D, Convolution3D, MaxPooling3D, ZeroPadding3D\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.optimizers import Adam, RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## video models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T18:19:29.805802Z",
     "start_time": "2020-03-24T18:19:29.801179Z"
    }
   },
   "outputs": [],
   "source": [
    "experiments = [experiment1, experiment2, experiment3, experiment4, experiment5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T09:05:39.902990Z",
     "start_time": "2020-03-25T09:05:39.900219Z"
    }
   },
   "outputs": [],
   "source": [
    "class_names = ['noseal',\n",
    "'seal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T19:40:12.052001Z",
     "start_time": "2020-03-24T19:26:44.528054Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 5\n",
      "predicting frame 0 on video s1-218\n",
      "predicting frame 0 on video s10-6558\n",
      "predicting frame 0 on video s11-7363\n",
      "predicting frame 0 on video s12-3465\n",
      "predicting frame 500 on video s12-3465\n",
      "predicting frame 0 on video s13-14\n",
      "predicting frame 0 on video s14-1705\n",
      "predicting frame 0 on video s15-2589\n",
      "predicting frame 0 on video s16-0\n",
      "predicting frame 0 on video s17-2973\n",
      "predicting frame 0 on video s18-630\n",
      "predicting frame 0 on video s19-672\n",
      "predicting frame 0 on video s2-1133\n",
      "predicting frame 0 on video s20-842\n",
      "predicting frame 0 on video s21-919\n",
      "predicting frame 0 on video s22-3733\n",
      "predicting frame 0 on video s23-4847\n",
      "predicting frame 0 on video s24-5851\n",
      "predicting frame 0 on video s25-5886\n",
      "predicting frame 0 on video s26-8164\n",
      "predicting frame 0 on video s27-8212\n",
      "predicting frame 0 on video s28-20\n",
      "predicting frame 0 on video s29-316\n",
      "predicting frame 0 on video s3-1993\n",
      "predicting frame 0 on video s30-516\n",
      "predicting frame 0 on video s31-784\n",
      "predicting frame 0 on video s32-3110\n",
      "predicting frame 500 on video s32-3110\n",
      "predicting frame 1000 on video s32-3110\n",
      "predicting frame 0 on video s33-3405\n",
      "predicting frame 0 on video s34-3590\n",
      "predicting frame 0 on video s35-3664\n",
      "predicting frame 0 on video s36-3838\n",
      "predicting frame 0 on video s37-3930\n",
      "predicting frame 0 on video s38-4060\n",
      "predicting frame 0 on video s39-4336\n",
      "predicting frame 0 on video s4-6975\n",
      "predicting frame 0 on video s40-4508\n",
      "predicting frame 0 on video s41-4712\n",
      "predicting frame 0 on video s42-4950\n",
      "predicting frame 0 on video s43-5211\n",
      "predicting frame 0 on video s44-5304\n",
      "predicting frame 0 on video s45-6301\n",
      "predicting frame 0 on video s46-8087\n",
      "predicting frame 0 on video s5-1102\n",
      "predicting frame 0 on video s6-1247\n",
      "predicting frame 500 on video s6-1247\n",
      "predicting frame 0 on video s7-2029\n",
      "predicting frame 0 on video s8-2244\n",
      "predicting frame 500 on video s8-2244\n",
      "predicting frame 0 on video s9-5491\n",
      "2 5\n",
      "predicting frame 0 on video s1-218\n",
      "predicting frame 0 on video s10-6558\n",
      "predicting frame 0 on video s11-7363\n",
      "predicting frame 0 on video s12-3465\n",
      "predicting frame 500 on video s12-3465\n",
      "predicting frame 0 on video s13-14\n",
      "predicting frame 0 on video s14-1705\n",
      "predicting frame 0 on video s15-2589\n",
      "predicting frame 0 on video s16-0\n",
      "predicting frame 0 on video s17-2973\n",
      "predicting frame 0 on video s18-630\n",
      "predicting frame 0 on video s19-672\n",
      "predicting frame 0 on video s2-1133\n",
      "predicting frame 0 on video s20-842\n",
      "predicting frame 0 on video s21-919\n",
      "predicting frame 0 on video s22-3733\n",
      "predicting frame 0 on video s23-4847\n",
      "predicting frame 0 on video s24-5851\n",
      "predicting frame 0 on video s25-5886\n",
      "predicting frame 0 on video s26-8164\n",
      "predicting frame 0 on video s27-8212\n",
      "predicting frame 0 on video s28-20\n",
      "predicting frame 0 on video s29-316\n",
      "predicting frame 0 on video s3-1993\n",
      "predicting frame 0 on video s30-516\n",
      "predicting frame 0 on video s31-784\n",
      "predicting frame 0 on video s32-3110\n",
      "predicting frame 500 on video s32-3110\n",
      "predicting frame 1000 on video s32-3110\n",
      "predicting frame 0 on video s33-3405\n",
      "predicting frame 0 on video s34-3590\n",
      "predicting frame 0 on video s35-3664\n",
      "predicting frame 0 on video s36-3838\n",
      "predicting frame 0 on video s37-3930\n",
      "predicting frame 0 on video s38-4060\n",
      "predicting frame 0 on video s39-4336\n",
      "predicting frame 0 on video s4-6975\n",
      "predicting frame 0 on video s40-4508\n",
      "predicting frame 0 on video s41-4712\n",
      "predicting frame 0 on video s42-4950\n",
      "predicting frame 0 on video s43-5211\n",
      "predicting frame 0 on video s44-5304\n",
      "predicting frame 0 on video s45-6301\n",
      "predicting frame 0 on video s46-8087\n",
      "predicting frame 0 on video s5-1102\n",
      "predicting frame 0 on video s6-1247\n",
      "predicting frame 500 on video s6-1247\n",
      "predicting frame 0 on video s7-2029\n",
      "predicting frame 0 on video s8-2244\n",
      "predicting frame 500 on video s8-2244\n",
      "predicting frame 0 on video s9-5491\n",
      "3 3\n",
      "predicting frame 0 on video s1-218\n",
      "predicting frame 0 on video s10-6558\n",
      "predicting frame 0 on video s11-7363\n",
      "predicting frame 0 on video s12-3465\n",
      "predicting frame 500 on video s12-3465\n",
      "predicting frame 0 on video s13-14\n",
      "predicting frame 0 on video s14-1705\n",
      "predicting frame 0 on video s15-2589\n",
      "predicting frame 0 on video s16-0\n",
      "predicting frame 0 on video s17-2973\n",
      "predicting frame 0 on video s18-630\n",
      "predicting frame 0 on video s19-672\n",
      "predicting frame 0 on video s2-1133\n",
      "predicting frame 0 on video s20-842\n",
      "predicting frame 0 on video s21-919\n",
      "predicting frame 0 on video s22-3733\n",
      "predicting frame 0 on video s23-4847\n",
      "predicting frame 0 on video s24-5851\n",
      "predicting frame 0 on video s25-5886\n",
      "predicting frame 0 on video s26-8164\n",
      "predicting frame 0 on video s27-8212\n",
      "predicting frame 0 on video s28-20\n",
      "predicting frame 0 on video s29-316\n",
      "predicting frame 0 on video s3-1993\n",
      "predicting frame 0 on video s30-516\n",
      "predicting frame 0 on video s31-784\n",
      "predicting frame 0 on video s32-3110\n",
      "predicting frame 500 on video s32-3110\n",
      "predicting frame 1000 on video s32-3110\n",
      "predicting frame 0 on video s33-3405\n",
      "predicting frame 0 on video s34-3590\n",
      "predicting frame 0 on video s35-3664\n",
      "predicting frame 0 on video s36-3838\n",
      "predicting frame 0 on video s37-3930\n",
      "predicting frame 0 on video s38-4060\n",
      "predicting frame 0 on video s39-4336\n",
      "predicting frame 0 on video s4-6975\n",
      "predicting frame 0 on video s40-4508\n",
      "predicting frame 0 on video s41-4712\n",
      "predicting frame 0 on video s42-4950\n",
      "predicting frame 0 on video s43-5211\n",
      "predicting frame 0 on video s44-5304\n",
      "predicting frame 0 on video s45-6301\n",
      "predicting frame 0 on video s46-8087\n",
      "predicting frame 0 on video s5-1102\n",
      "predicting frame 0 on video s6-1247\n",
      "predicting frame 500 on video s6-1247\n",
      "predicting frame 0 on video s7-2029\n",
      "predicting frame 0 on video s8-2244\n",
      "predicting frame 500 on video s8-2244\n",
      "predicting frame 0 on video s9-5491\n",
      "4 5\n",
      "predicting frame 0 on video s1-218\n",
      "predicting frame 0 on video s10-6558\n",
      "predicting frame 0 on video s11-7363\n",
      "predicting frame 0 on video s12-3465\n",
      "predicting frame 500 on video s12-3465\n",
      "predicting frame 0 on video s13-14\n",
      "predicting frame 0 on video s14-1705\n",
      "predicting frame 0 on video s15-2589\n",
      "predicting frame 0 on video s16-0\n",
      "predicting frame 0 on video s17-2973\n",
      "predicting frame 0 on video s18-630\n",
      "predicting frame 0 on video s19-672\n",
      "predicting frame 0 on video s2-1133\n",
      "predicting frame 0 on video s20-842\n",
      "predicting frame 0 on video s21-919\n",
      "predicting frame 0 on video s22-3733\n",
      "predicting frame 0 on video s23-4847\n",
      "predicting frame 0 on video s24-5851\n",
      "predicting frame 0 on video s25-5886\n",
      "predicting frame 0 on video s26-8164\n",
      "predicting frame 0 on video s27-8212\n",
      "predicting frame 0 on video s28-20\n",
      "predicting frame 0 on video s29-316\n",
      "predicting frame 0 on video s3-1993\n",
      "predicting frame 0 on video s30-516\n",
      "predicting frame 0 on video s31-784\n",
      "predicting frame 0 on video s32-3110\n",
      "predicting frame 500 on video s32-3110\n",
      "predicting frame 1000 on video s32-3110\n",
      "predicting frame 0 on video s33-3405\n",
      "predicting frame 0 on video s34-3590\n",
      "predicting frame 0 on video s35-3664\n",
      "predicting frame 0 on video s36-3838\n",
      "predicting frame 0 on video s37-3930\n",
      "predicting frame 0 on video s38-4060\n",
      "predicting frame 0 on video s39-4336\n",
      "predicting frame 0 on video s4-6975\n",
      "predicting frame 0 on video s40-4508\n",
      "predicting frame 0 on video s41-4712\n",
      "predicting frame 0 on video s42-4950\n",
      "predicting frame 0 on video s43-5211\n",
      "predicting frame 0 on video s44-5304\n",
      "predicting frame 0 on video s45-6301\n",
      "predicting frame 0 on video s46-8087\n",
      "predicting frame 0 on video s5-1102\n",
      "predicting frame 0 on video s6-1247\n",
      "predicting frame 500 on video s6-1247\n",
      "predicting frame 0 on video s7-2029\n",
      "predicting frame 0 on video s8-2244\n",
      "predicting frame 500 on video s8-2244\n",
      "predicting frame 0 on video s9-5491\n",
      "5 5\n",
      "predicting frame 0 on video s1-218\n",
      "predicting frame 0 on video s10-6558\n",
      "predicting frame 0 on video s11-7363\n",
      "predicting frame 0 on video s12-3465\n",
      "predicting frame 500 on video s12-3465\n",
      "predicting frame 0 on video s13-14\n",
      "predicting frame 0 on video s14-1705\n",
      "predicting frame 0 on video s15-2589\n",
      "predicting frame 0 on video s16-0\n",
      "predicting frame 0 on video s17-2973\n",
      "predicting frame 0 on video s18-630\n",
      "predicting frame 0 on video s19-672\n",
      "predicting frame 0 on video s2-1133\n",
      "predicting frame 0 on video s20-842\n",
      "predicting frame 0 on video s21-919\n",
      "predicting frame 0 on video s22-3733\n",
      "predicting frame 0 on video s23-4847\n",
      "predicting frame 0 on video s24-5851\n",
      "predicting frame 0 on video s25-5886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting frame 0 on video s26-8164\n",
      "predicting frame 0 on video s27-8212\n",
      "predicting frame 0 on video s28-20\n",
      "predicting frame 0 on video s29-316\n",
      "predicting frame 0 on video s3-1993\n",
      "predicting frame 0 on video s30-516\n",
      "predicting frame 0 on video s31-784\n",
      "predicting frame 0 on video s32-3110\n",
      "predicting frame 500 on video s32-3110\n",
      "predicting frame 1000 on video s32-3110\n",
      "predicting frame 0 on video s33-3405\n",
      "predicting frame 0 on video s34-3590\n",
      "predicting frame 0 on video s35-3664\n",
      "predicting frame 0 on video s36-3838\n",
      "predicting frame 0 on video s37-3930\n",
      "predicting frame 0 on video s38-4060\n",
      "predicting frame 0 on video s39-4336\n",
      "predicting frame 0 on video s4-6975\n",
      "predicting frame 0 on video s40-4508\n",
      "predicting frame 0 on video s41-4712\n",
      "predicting frame 0 on video s42-4950\n",
      "predicting frame 0 on video s43-5211\n",
      "predicting frame 0 on video s44-5304\n",
      "predicting frame 0 on video s45-6301\n",
      "predicting frame 0 on video s46-8087\n",
      "predicting frame 0 on video s5-1102\n",
      "predicting frame 0 on video s6-1247\n",
      "predicting frame 500 on video s6-1247\n",
      "predicting frame 0 on video s7-2029\n",
      "predicting frame 0 on video s8-2244\n",
      "predicting frame 500 on video s8-2244\n",
      "predicting frame 0 on video s9-5491\n"
     ]
    }
   ],
   "source": [
    "for experiment in experiments:\n",
    "    model_id = experiment['model_id']\n",
    "    sequence_length = experiment['sequence_length']\n",
    "    print(model_id, sequence_length)\n",
    "\n",
    "    # load model and labels\n",
    "    model = load_model(pwd + 'models/' + str(model_id) + '/model_best.h5')\n",
    "    labels = pd.read_csv(path_data + \"labels.csv\")\n",
    "    labels['idx'] = labels['frame'].str.split(\"-\").str.get(-1).str.split(\".\").str.get(0).astype(int)\n",
    "    videos = list(labels['video'].unique())\n",
    "\n",
    "    # build CSV with frame predictions and ground truth\n",
    "    fps = []\n",
    "\n",
    "    for video in videos:\n",
    "\n",
    "        # load features then construct frame blocks and predict using model\n",
    "        features = np.load(\"/mnt/seals/cache/features/resnet50/max/\" + video + '.npy') \n",
    "\n",
    "        frame_predictions = []\n",
    "        for c, feature in enumerate(features):\n",
    "            if c % 500 == 0:\n",
    "                print (\"predicting frame {} on video {}\".format(c, video))\n",
    "            if c >= sequence_length:\n",
    "                clip = features[c-sequence_length:c,:]\n",
    "                clip = np.expand_dims(clip, axis=0)\n",
    "                frame_prediction = model.predict(clip)\n",
    "                frame_predictions.append(frame_prediction)\n",
    "\n",
    "        # flatten into dataframe\n",
    "        fp = np.array(frame_predictions)\n",
    "        fp = np.squeeze(fp,axis=1)\n",
    "        fp = pd.DataFrame(fp)\n",
    "        fp.index = fp.index + sequence_length - 1\n",
    "        fp.columns = class_names\n",
    "        fp['prediction'] = fp.idxmax(axis=1)\n",
    "        labels_vid = labels[labels['video'] == video]\n",
    "        labels_vid.reset_index(inplace=True,drop=True)\n",
    "        fp = pd.merge(fp, labels_vid, left_index=True,right_index=True,how='left')\n",
    "        fps.append(fp)\n",
    "\n",
    "    # output\n",
    "    df = pd.concat(fps)\n",
    "    df['error'] = (df['prediction'] != df['label']).astype(int)\n",
    "    df.to_csv(pwd + 'models/' + str(model_id) + '/frame_predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## image only model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T09:05:43.852773Z",
     "start_time": "2020-03-25T09:05:43.848466Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'architecture': 'image_mlp_frozen',\n",
       " 'dropout': 0.2,\n",
       " 'layer_1_size': 128,\n",
       " 'layer_2_size': 512,\n",
       " 'layer_3_size': 128,\n",
       " 'model_id': 6,\n",
       " 'pooling': 'max',\n",
       " 'pretrained_model_name': 'resnet50',\n",
       " 'sequence_length': 1,\n",
       " 'sequence_model': '',\n",
       " 'sequence_model_layers': ''}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment = experiment6\n",
    "experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T09:06:12.393409Z",
     "start_time": "2020-03-25T09:05:44.368824Z"
    }
   },
   "outputs": [],
   "source": [
    "model_id = experiment['model_id']\n",
    "\n",
    "# load model and labels\n",
    "model = load_model(pwd + 'models/' + str(model_id) + '/model_best.h5')\n",
    "labels = pd.read_csv(path_data + \"labels.csv\")\n",
    "labels['idx'] = labels['frame'].str.split(\"-\").str.get(-1).str.split(\".\").str.get(0).astype(int)\n",
    "videos = list(labels['video'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T09:06:51.521033Z",
     "start_time": "2020-03-25T09:06:12.395819Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XXX s1-218 138\n",
      "XXX s10-6558 184\n",
      "XXX s11-7363 303\n",
      "XXX s12-3465 644\n",
      "XXX s13-14 156\n",
      "XXX s14-1705 129\n",
      "XXX s15-2589 147\n",
      "XXX s16-0 129\n",
      "XXX s17-2973 294\n",
      "XXX s18-630 350\n",
      "XXX s19-672 166\n",
      "XXX s2-1133 156\n",
      "XXX s20-842 331\n",
      "XXX s21-919 147\n",
      "XXX s22-3733 129\n",
      "XXX s23-4847 156\n",
      "XXX s24-5851 138\n",
      "XXX s25-5886 193\n",
      "XXX s26-8164 266\n",
      "XXX s27-8212 174\n",
      "XXX s28-20 285\n",
      "XXX s29-316 405\n",
      "XXX s3-1993 184\n",
      "XXX s30-516 156\n",
      "XXX s31-784 193\n",
      "XXX s32-3110 1407\n",
      "XXX s33-3405 313\n",
      "XXX s34-3590 266\n",
      "XXX s35-3664 147\n",
      "XXX s36-3838 230\n",
      "XXX s37-3930 119\n",
      "XXX s38-4060 303\n",
      "XXX s39-4336 239\n",
      "XXX s4-6975 129\n",
      "XXX s40-4508 377\n",
      "XXX s41-4712 368\n",
      "XXX s42-4950 221\n",
      "XXX s43-5211 221\n",
      "XXX s44-5304 129\n",
      "XXX s45-6301 147\n",
      "XXX s46-8087 166\n",
      "XXX s5-1102 303\n",
      "XXX s6-1247 589\n",
      "XXX s7-2029 395\n",
      "XXX s8-2244 634\n",
      "XXX s9-5491 202\n"
     ]
    }
   ],
   "source": [
    "# build CSV with frame predictions and ground truth\n",
    "fps = []\n",
    "\n",
    "for video in videos:\n",
    "\n",
    "    # load features then construct frame blocks and predict using model\n",
    "    features = np.load(\"/mnt/seals/cache/features/resnet50/max/\" + video + '.npy') \n",
    "\n",
    "    frame_predictions = []\n",
    "    for c, feature in enumerate(features):\n",
    "#         if c % 500 == 0:\n",
    "#             print (\"predicting frame {} on video {}\".format(c, video))\n",
    "        frame_prediction = model.predict(np.expand_dims(feature, axis=0))\n",
    "        frame_predictions.append(frame_prediction)\n",
    "\n",
    "    # flatten into dataframe\n",
    "    fp = np.array(frame_predictions)\n",
    "    fp = np.squeeze(fp,axis=1)\n",
    "    fp = pd.DataFrame(fp)\n",
    "    fp.columns = class_names\n",
    "    fp['prediction'] = fp.idxmax(axis=1)\n",
    "    labels_vid = labels[labels['video'] == video]\n",
    "    labels_vid.reset_index(inplace=True,drop=True)\n",
    "    fp = pd.merge(fp, labels_vid, left_index=True,right_index=True,how='left')\n",
    "    fps.append(fp)\n",
    "    print(\"XXX\", video, len(fp))\n",
    "\n",
    "# output\n",
    "df = pd.concat(fps)\n",
    "df['error'] = (df['prediction'] != df['label']).astype(int)\n",
    "df.to_csv(pwd + 'models/' + str(model_id) + '/frame_predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## concat model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T19:41:17.070431Z",
     "start_time": "2020-03-24T19:41:17.066391Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'architecture': 'video_mlp_concat',\n",
       " 'dropout': 0.2,\n",
       " 'layer_1_size': 128,\n",
       " 'layer_2_size': 128,\n",
       " 'layer_3_size': 512,\n",
       " 'model_id': 7,\n",
       " 'pooling': 'max',\n",
       " 'pretrained_model_name': 'resnet50',\n",
       " 'sequence_length': 3,\n",
       " 'sequence_model': '',\n",
       " 'sequence_model_layers': ''}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment = experiment7\n",
    "experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T19:41:44.538766Z",
     "start_time": "2020-03-24T19:41:17.072343Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 3\n"
     ]
    }
   ],
   "source": [
    "model_id = experiment['model_id']\n",
    "sequence_length = experiment['sequence_length']\n",
    "print(model_id, sequence_length)\n",
    "\n",
    "# load model and labels\n",
    "model = load_model(pwd + 'models/' + str(model_id) + '/model_best.h5')\n",
    "labels = pd.read_csv(path_data + \"labels.csv\")\n",
    "labels['idx'] = labels['frame'].str.split(\"-\").str.get(-1).str.split(\".\").str.get(0).astype(int)\n",
    "videos = list(labels['video'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T19:42:25.748675Z",
     "start_time": "2020-03-24T19:41:44.541200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting frame 0 on video s1-218\n",
      "predicting frame 0 on video s10-6558\n",
      "predicting frame 0 on video s11-7363\n",
      "predicting frame 0 on video s12-3465\n",
      "predicting frame 500 on video s12-3465\n",
      "predicting frame 0 on video s13-14\n",
      "predicting frame 0 on video s14-1705\n",
      "predicting frame 0 on video s15-2589\n",
      "predicting frame 0 on video s16-0\n",
      "predicting frame 0 on video s17-2973\n",
      "predicting frame 0 on video s18-630\n",
      "predicting frame 0 on video s19-672\n",
      "predicting frame 0 on video s2-1133\n",
      "predicting frame 0 on video s20-842\n",
      "predicting frame 0 on video s21-919\n",
      "predicting frame 0 on video s22-3733\n",
      "predicting frame 0 on video s23-4847\n",
      "predicting frame 0 on video s24-5851\n",
      "predicting frame 0 on video s25-5886\n",
      "predicting frame 0 on video s26-8164\n",
      "predicting frame 0 on video s27-8212\n",
      "predicting frame 0 on video s28-20\n",
      "predicting frame 0 on video s29-316\n",
      "predicting frame 0 on video s3-1993\n",
      "predicting frame 0 on video s30-516\n",
      "predicting frame 0 on video s31-784\n",
      "predicting frame 0 on video s32-3110\n",
      "predicting frame 500 on video s32-3110\n",
      "predicting frame 1000 on video s32-3110\n",
      "predicting frame 0 on video s33-3405\n",
      "predicting frame 0 on video s34-3590\n",
      "predicting frame 0 on video s35-3664\n",
      "predicting frame 0 on video s36-3838\n",
      "predicting frame 0 on video s37-3930\n",
      "predicting frame 0 on video s38-4060\n",
      "predicting frame 0 on video s39-4336\n",
      "predicting frame 0 on video s4-6975\n",
      "predicting frame 0 on video s40-4508\n",
      "predicting frame 0 on video s41-4712\n",
      "predicting frame 0 on video s42-4950\n",
      "predicting frame 0 on video s43-5211\n",
      "predicting frame 0 on video s44-5304\n",
      "predicting frame 0 on video s45-6301\n",
      "predicting frame 0 on video s46-8087\n",
      "predicting frame 0 on video s5-1102\n",
      "predicting frame 0 on video s6-1247\n",
      "predicting frame 500 on video s6-1247\n",
      "predicting frame 0 on video s7-2029\n",
      "predicting frame 0 on video s8-2244\n",
      "predicting frame 500 on video s8-2244\n",
      "predicting frame 0 on video s9-5491\n"
     ]
    }
   ],
   "source": [
    "# build CSV with frame predictions and ground truth\n",
    "fps = []\n",
    "\n",
    "for video in videos:\n",
    "\n",
    "    # load features then construct frame blocks and predict using model\n",
    "    features = np.load(\"/mnt/seals/cache/features/resnet50/max/\" + video + '.npy') \n",
    "\n",
    "    frame_predictions = []\n",
    "    for c, feature in enumerate(features):\n",
    "        if c % 500 == 0:\n",
    "            print (\"predicting frame {} on video {}\".format(c, video))\n",
    "        if c >= sequence_length:\n",
    "            clip = features[c-sequence_length:c,:]\n",
    "            clip = np.expand_dims(clip, axis=0)\n",
    "            frame_prediction = model.predict(clip)\n",
    "            frame_predictions.append(frame_prediction)\n",
    "\n",
    "    # flatten into dataframe\n",
    "    fp = np.array(frame_predictions)\n",
    "    fp = np.squeeze(fp,axis=1)\n",
    "    fp = pd.DataFrame(fp)\n",
    "    fp.index = fp.index + sequence_length - 1\n",
    "    fp.columns = class_names\n",
    "    fp['prediction'] = fp.idxmax(axis=1)\n",
    "    labels_vid = labels[labels['video'] == video]\n",
    "    labels_vid.reset_index(inplace=True,drop=True)\n",
    "    fp = pd.merge(fp, labels_vid, left_index=True,right_index=True,how='left')\n",
    "    fps.append(fp)\n",
    "\n",
    "# output\n",
    "df = pd.concat(fps)\n",
    "df['error'] = (df['prediction'] != df['label']).astype(int)\n",
    "df.to_csv(pwd + 'models/' + str(model_id) + '/frame_predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T09:07:34.212243Z",
     "start_time": "2020-03-25T09:07:34.209333Z"
    }
   },
   "outputs": [],
   "source": [
    "path_ship = pwd + \"ship/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T09:07:34.818677Z",
     "start_time": "2020-03-25T09:07:34.814224Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['params.json',\n",
       " 'confusion_matrix.png',\n",
       " 'model_best.h5',\n",
       " 'confusion_matrix.csv',\n",
       " 'training_round_3.log',\n",
       " 'fit_history.csv',\n",
       " 'model_config.h5',\n",
       " 'model_round_2.h5',\n",
       " 'model_summary.txt',\n",
       " 'training_round_2.log',\n",
       " 'model_round_3.h5',\n",
       " 'training_round_1.log',\n",
       " 'confusion_matrix_normalized.png',\n",
       " 'results.json',\n",
       " 'model_round_1.h5',\n",
       " 'test_predictions.npy',\n",
       " 'frame_predictions.csv']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(path_ship + '/1/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## delete models and logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T09:07:38.494380Z",
     "start_time": "2020-03-25T09:07:38.489273Z"
    }
   },
   "outputs": [],
   "source": [
    "paths = []\n",
    "for folder, subs, files in os.walk(path_ship):        \n",
    "    for filename in files:\n",
    "        if filename[-3:] == '.h5' or  filename[-4:] == '.npy' or  filename[-4:] == '.log':\n",
    "            paths.append(os.path.abspath(os.path.join(folder, filename)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T09:07:40.256340Z",
     "start_time": "2020-03-25T09:07:39.992055Z"
    }
   },
   "outputs": [],
   "source": [
    "for p in paths:\n",
    "    os.remove(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## aggregate results into csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T09:07:41.120535Z",
     "start_time": "2020-03-25T09:07:41.116314Z"
    }
   },
   "outputs": [],
   "source": [
    "paths = []\n",
    "for folder, subs, files in os.walk(path_ship):        \n",
    "    for filename in files:\n",
    "        if 'results' in filename:\n",
    "            paths.append(os.path.abspath(os.path.join(folder, filename)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T09:07:42.572272Z",
     "start_time": "2020-03-25T09:07:42.568018Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/seals/ship/3/results.json',\n",
       " '/mnt/seals/ship/2/results.json',\n",
       " '/mnt/seals/ship/1/results.json',\n",
       " '/mnt/seals/ship/5/results.json',\n",
       " '/mnt/seals/ship/6/results.json',\n",
       " '/mnt/seals/ship/4/results.json',\n",
       " '/mnt/seals/ship/7/results.json']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T09:07:42.731527Z",
     "start_time": "2020-03-25T09:07:42.728741Z"
    }
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T09:07:43.253892Z",
     "start_time": "2020-03-25T09:07:43.243056Z"
    }
   },
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for path in paths:\n",
    "    with open(path) as json_file:\n",
    "        data = json.load(json_file)\n",
    "        df = pd.DataFrame.from_dict(data, orient=\"index\").T\n",
    "        dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T09:07:44.794365Z",
     "start_time": "2020-03-25T09:07:44.789585Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.concat(dfs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T09:07:45.150730Z",
     "start_time": "2020-03-25T09:07:45.119169Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_weights_path</th>\n",
       "      <th>dropout</th>\n",
       "      <th>data_total_rows_train</th>\n",
       "      <th>layer_2_size</th>\n",
       "      <th>frame_size</th>\n",
       "      <th>fit_best_round</th>\n",
       "      <th>fit_stopped_epoch1</th>\n",
       "      <th>fit_dt_test_duration_seconds</th>\n",
       "      <th>convolution_kernel_size</th>\n",
       "      <th>pretrained_model_name</th>\n",
       "      <th>...</th>\n",
       "      <th>model_id</th>\n",
       "      <th>architecture</th>\n",
       "      <th>fit_dt_train_end</th>\n",
       "      <th>data_total_rows_valid</th>\n",
       "      <th>sequence_model</th>\n",
       "      <th>fit_dt_test_end</th>\n",
       "      <th>data_total_rows_test</th>\n",
       "      <th>fit_val_loss</th>\n",
       "      <th>model_param_count</th>\n",
       "      <th>fit_dt_train_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10697</td>\n",
       "      <td>512</td>\n",
       "      <td>[224, 224]</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>video_lrcnn_frozen</td>\n",
       "      <td>2020-03-24 18:03:46</td>\n",
       "      <td>1370</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>2020-03-24 18:03:52</td>\n",
       "      <td>299</td>\n",
       "      <td>0.140319</td>\n",
       "      <td>7541122</td>\n",
       "      <td>2020-03-24 17:58:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10619</td>\n",
       "      <td>512</td>\n",
       "      <td>[224, 224]</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>video_lrcnn_frozen</td>\n",
       "      <td>2020-03-24 17:58:11</td>\n",
       "      <td>1360</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>2020-03-24 17:58:16</td>\n",
       "      <td>295</td>\n",
       "      <td>0.140141</td>\n",
       "      <td>8000258</td>\n",
       "      <td>2020-03-24 17:52:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10619</td>\n",
       "      <td>128</td>\n",
       "      <td>[224, 224]</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>video_lrcnn_frozen</td>\n",
       "      <td>2020-03-24 17:52:37</td>\n",
       "      <td>1360</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>2020-03-24 17:52:41</td>\n",
       "      <td>295</td>\n",
       "      <td>0.146982</td>\n",
       "      <td>1410818</td>\n",
       "      <td>2020-03-24 17:48:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10619</td>\n",
       "      <td>128</td>\n",
       "      <td>[224, 224]</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>video_lrcnn_frozen</td>\n",
       "      <td>2020-03-24 18:15:01</td>\n",
       "      <td>1360</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>2020-03-24 18:15:08</td>\n",
       "      <td>295</td>\n",
       "      <td>0.131391</td>\n",
       "      <td>2557698</td>\n",
       "      <td>2020-03-24 18:09:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10775</td>\n",
       "      <td>512</td>\n",
       "      <td>[224, 224]</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>image_mlp_frozen</td>\n",
       "      <td>2020-03-24 18:17:18</td>\n",
       "      <td>1380</td>\n",
       "      <td></td>\n",
       "      <td>2020-03-24 18:17:25</td>\n",
       "      <td>303</td>\n",
       "      <td>0.18904</td>\n",
       "      <td>394242</td>\n",
       "      <td>2020-03-24 18:15:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10619</td>\n",
       "      <td>512</td>\n",
       "      <td>[224, 224]</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>video_lrcnn_frozen</td>\n",
       "      <td>2020-03-24 18:09:03</td>\n",
       "      <td>1360</td>\n",
       "      <td>GRU</td>\n",
       "      <td>2020-03-24 18:09:09</td>\n",
       "      <td>295</td>\n",
       "      <td>0.171778</td>\n",
       "      <td>6820354</td>\n",
       "      <td>2020-03-24 18:03:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10697</td>\n",
       "      <td>128</td>\n",
       "      <td>[224, 224]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>video_mlp_concat</td>\n",
       "      <td>2020-03-24 18:19:18</td>\n",
       "      <td>1370</td>\n",
       "      <td></td>\n",
       "      <td>2020-03-24 18:19:26</td>\n",
       "      <td>299</td>\n",
       "      <td>4.75057</td>\n",
       "      <td>870146</td>\n",
       "      <td>2020-03-24 18:17:29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows  39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_weights_path dropout data_total_rows_train layer_2_size  frame_size  \\\n",
       "0               None     0.2                 10697          512  [224, 224]   \n",
       "0               None     0.2                 10619          512  [224, 224]   \n",
       "0               None     0.2                 10619          128  [224, 224]   \n",
       "0               None     0.2                 10619          128  [224, 224]   \n",
       "0               None     0.2                 10775          512  [224, 224]   \n",
       "0               None     0.2                 10619          512  [224, 224]   \n",
       "0               None     0.2                 10697          128  [224, 224]   \n",
       "\n",
       "  fit_best_round fit_stopped_epoch1 fit_dt_test_duration_seconds  \\\n",
       "0              3                  9                            2   \n",
       "0              3                  6                            2   \n",
       "0              3                  7                            1   \n",
       "0              3                  6                            3   \n",
       "0              3                  9                            3   \n",
       "0              3                  5                            2   \n",
       "0              1                  1                            3   \n",
       "\n",
       "  convolution_kernel_size pretrained_model_name         ...          model_id  \\\n",
       "0                       3              resnet50         ...                 3   \n",
       "0                       3              resnet50         ...                 2   \n",
       "0                       3              resnet50         ...                 1   \n",
       "0                       3              resnet50         ...                 5   \n",
       "0                       3              resnet50         ...                 6   \n",
       "0                       3              resnet50         ...                 4   \n",
       "0                       3              resnet50         ...                 7   \n",
       "\n",
       "         architecture     fit_dt_train_end data_total_rows_valid  \\\n",
       "0  video_lrcnn_frozen  2020-03-24 18:03:46                  1370   \n",
       "0  video_lrcnn_frozen  2020-03-24 17:58:11                  1360   \n",
       "0  video_lrcnn_frozen  2020-03-24 17:52:37                  1360   \n",
       "0  video_lrcnn_frozen  2020-03-24 18:15:01                  1360   \n",
       "0    image_mlp_frozen  2020-03-24 18:17:18                  1380   \n",
       "0  video_lrcnn_frozen  2020-03-24 18:09:03                  1360   \n",
       "0    video_mlp_concat  2020-03-24 18:19:18                  1370   \n",
       "\n",
       "  sequence_model      fit_dt_test_end data_total_rows_test fit_val_loss  \\\n",
       "0           LSTM  2020-03-24 18:03:52                  299     0.140319   \n",
       "0           LSTM  2020-03-24 17:58:16                  295     0.140141   \n",
       "0           LSTM  2020-03-24 17:52:41                  295     0.146982   \n",
       "0           LSTM  2020-03-24 18:15:08                  295     0.131391   \n",
       "0                 2020-03-24 18:17:25                  303      0.18904   \n",
       "0            GRU  2020-03-24 18:09:09                  295     0.171778   \n",
       "0                 2020-03-24 18:19:26                  299      4.75057   \n",
       "\n",
       "  model_param_count   fit_dt_train_start  \n",
       "0           7541122  2020-03-24 17:58:20  \n",
       "0           8000258  2020-03-24 17:52:45  \n",
       "0           1410818  2020-03-24 17:48:20  \n",
       "0           2557698  2020-03-24 18:09:14  \n",
       "0            394242  2020-03-24 18:15:12  \n",
       "0           6820354  2020-03-24 18:03:56  \n",
       "0            870146  2020-03-24 18:17:29  \n",
       "\n",
       "[7 rows x 39 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T09:07:48.270528Z",
     "start_time": "2020-03-25T09:07:48.264808Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv(path_ship + \"results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
